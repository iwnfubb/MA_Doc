\chapter{Ergebnisse und Evaluation}\label{chp:ergebnisse}
Die festgelegten Ziele in Abschnitt \ref{chp:Ziele} wurden in der fertig entwickelten Anwendung vollständig erreicht. Um die Qualität der Software zu überprüfen, wurden eine Reihe von selbst erstellten Testvideos als Eingabe verwendet. Diese Videos wurden bei Bosch in zwei dafür vorgesehenen Räumen gedreht. Um das entwickelte Programm zu testen, wurden in den Videos einige Szenarien von Personen in verschiedenen Situationen simuliert. Die außergewöhnliche Situationen sind von $30\%$ bis $40\%$ in den Testvideos vorhanden. Dabei sollte die Software erkennen, ob es sich um eine normale oder außergewöhnliche Situation handelt. In einigen Videos haben sich Personen auf den Boden gelegt und sich dann nicht mehr in $bad\_frames\_limit=30$ Frames bewegt. Diese Situation sollte als einen Unfall erkannt werden. In anderen Videos setzten sich Personen auf ein Sofa und schliefen ein. Dabei wurden die Situation bei Tag und Nacht sowie bei variierenden Anzahl an Personen im Raum aufgenommen. Dabei konnten die Menschen das Zimmer verlassen und wieder hineinkommen, um zu überprüfen, ob sie erneut von der Software erkannt wurden. Das Programm hat in allen Fällen gute Ergebnisse geliefert. Die Software konnte dabei nicht jeden Frame der Kamera richtig klassifizieren. Dennoch wurden alle außergewöhnlichen Situationen erkannt. Das folgt daraus, dass die außergewöhnlichen Situationen erst nach $t=30$ hintereinander folgenden Frames mit der Klassifizierung \glqq{}$bad$\grqq{} erkannt werden. Es gab somit bei manchen Situationen eine kleine Verzögerung, bis diese richtig klassifiziert wurden.\\

Die verwendete Kamera  hat eine Auflösung von 1080x720 Pixel und eine Frame-Rate von 15 FPS. Um einer Echtzeitanwendung gerecht zu werden, muss die Software damit mindestens 15 Bilder pro Sekunde klassifizieren und berechnen können. Dazu wurden einige Tests durchgeführt, um die Geschwindigkeit der Berechnung zu bestimmen. Es stellte sich heraus, dass das Programm durchschnittlich 59 Millisekunden pro Bild braucht, um dieses der zugehörigen Klasse zuzuordnen. Es kann somit 16 Frames jede Sekunde klassifizieren. Diese und die folgenden Tests wurden alle auf einem Rechner mit einem Intel i5 3,20 GHz Prozessor und 16 GB RAM.
In der folgenden Abbildung \ref{fig:laufzeit} wurde eine Laufzeitmessung mit 1000 Frames durchgeführt. Dabei wurde auf der X-Achse die Nummer des Bildes und auf der Y-Achse die dazugehörige Laufzeit abgetragen. Die rote Linie stellt die durchschnittliche Laufzeit dar.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/laufzeit.pdf}
	\caption{Gemessene Laufzeiten des Programms von 1000 Bildern.} 
	\label{fig:laufzeit}
\end{figure}

Die Anwendung wird sowohl mit ASB Methode als auch mit KNN-Plus-ASB Methode getestet. Außerdem wird eine Skalierung des Eingabebildes auf 854x450 Pixel durch KNN-Plus-ASB Methode angewendet, um das Programm zu bewerten. Die Abbildung \ref{fig:laufzeit3} stellt die durchschnittliche Laufzeit des Programms mit den ASB, KNN-Plus-ASB und Skalierung des Eingabebildes dar. Mit ASB braucht das Programm 22 Millisekunden und mit KNN-Plus-ASB sind 59 Millisekunden benötigt, um ein Bild zu verarbeiten. Mit einer Skalierung des Eingabebildes auf 854x450 Pixel wird das Verhältnis von der Breite und Höhe des Bildes nicht geändert und die durchschnittlichen Laufzeiten betrugen 29 Millisekunden.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{fig/laufzeit3.pdf}
	\caption{Gemessene Laufzeiten des Programm mit ASB, KNN-Plus-ASB und Skalierung des Eingabebildes.} 
	\label{fig:laufzeit3}
\end{figure}

In Abbildung \ref{fig:alarm} wurden drei Videos mit dem Programm untersucht. Die normalen und außergewöhnlichen Situationen in diesen Videos sind bereits bekannt. Die Software wurde zum analysieren der Frames verwendet und anschließend die Klassifikationen des Programms mit den bereits bekannten Zuordnungen der Bilder verglichen. Die X-Achse nummeriert die Frames und die Y-Achse stellt die Zuordnung des Bildes dar. Bei $y=1$ handelt es sich um eine normale Situation und bei $y=0$ um eine außergewöhnliche Situation. Die blaue Kurve stellt dabei die richtige bzw. bereits bekannte Zuordnung und die gelbe Kurve die berechnete Klassifikation dar.\\

\begin{figure}[H]
	\centering
	\includegraphics[width=0.65\textwidth]{fig/alarmevaluation2.pdf}
	\caption{Richtige Zuordnungen (blau) und berechnete Zuordnung (gelb) der Bilder grafisch dargestellt.} 
	\label{fig:alarm}
\end{figure}

Nicht alle Frames wurden durch das Programm richtig klassifiziert. Dennoch wurden mehr als $80\%$ der Bilder richtig zugeordnet. Die Erkennung außergewöhnlicher Situationen hängt dabei nicht von den einzelnen Frames ab. Eine solche Situation wird erst dann erkannt, wenn $30$ Frames hintereinander als außergewöhnlich klassifiziert werden. Daher konnte die Software, trotz kleinen Verzögerungen, alle außergewöhnlichen Situationen erkennen.\\
Um eine bessere Übersicht über die Zielgenauigkeit des Programms zu schaffen, wurden ROC-Kurven (siehe Abbildung \ref{fig:roc}) mit den implementierten Algorithmen sowie Verbesserungen aufgestellt.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/finalROC.pdf}
	\caption{ROC-Kurze zur Bewertung des Programms.} 
	\label{fig:roc}
\end{figure}

Während der Entwicklung der Software wurden zwei signifikante Methoden implementiert, um das Programm zu optimieren. Als Erstes wurde die ASB-Methode verwendet, die die Hintergrundsubtraktion verbessert. Da sonst zum Beispiel eine stehende Person in einem Raum, die sich lange nicht bewegt, ins Hintergrundbild aufgenommen und nicht mehr als \glqq{}sich bewegendes Objekt\grqq{} erkannt wird. Die zweite Modifikation ist die Kombination von der ASB-Methode und der KNN-Methode. Wobei die KNN-Methode die Genauigkeit der Hintergrundsubtraktion erhöht. In Abbildung \ref{fig:roc} wird der Unterschied bzw. die Verbesserungen anhand den einzelnen ROC-Kurven dargestellt. Um die Performance weiter zu optimieren, wurde das Bild vor der Verarbeitung herunter skaliert. Daraus entsteht ein Genauigkeitsverlust, der aber nicht stark genug ist, um die Qualität des Programms signifikant zu beeinflussen.



\begin{table}[H]
	\centering
	
	
	\begin{tabular}[H]{|c|c|cc|cc|c|}
		\hline 
		\multicolumn{2}{|c|}{\multirow{ 2}{*}{}} & \multicolumn{5}{c|}{abnormale Situation}\\
		\cline{3-7}
		\multicolumn{2}{|c|}{}& TNR & FNR & TPR & FPR & ACC\\
		\hline
		
		\multirow{ 2}{*}{\rotatebox[origin=c]{90}{{ Video 1 }}} & ASB & 0,869 & 0,037 & 0,962 & 0,0085 & 0,927\\
		
		& KNN-Plus-ASB & 0,762 & 0,11 & 0,889 & 0,053 & 0,917\\
		
		& 854x450 & 0,762 & 0,014 & 0,985 & 0,217 & 0,846\\
		
		\hline
		
		\multicolumn{7}{|c|}{}\\
		\hline
		\multirow{ 2}{*}{\rotatebox[origin=c]{90}{{ Video 2 }}} & ASB & 0,748 & 0,030 & 0,993 & 0,128 & 0,888\\
		
		& KNN-Plus-ASB & 0,763 & 0,024 & 0,996 & 0,111 & 0,903\\
		
		& 854x450 & 0,755 & 0,033 & 0,988 & 0,116 & 0,896\\
		\hline
		\multicolumn{7}{|c|}{}\\
		\hline
		\multirow{ 2}{*}{\rotatebox[origin=c]{90}{{ Video 3 }}} & ASB & 0,805 & 0,058 & 0,763 & 0,080 & 0,795\\
		
		& KNN-Plus-ASB & 0,956 & 0,029 & 0,881 & 0,014 & 0,938\\
		
		& 854x450 & 0,913 & 0,021 & 0,911 & 0,033 & 0,918\\
		\hline
	\end{tabular}
	\caption{Auswertung der verschiedenen Methoden mit ohne Skalierung des Bilds.}
	\label{tbl:auswertung}
\end{table}

In Tabelle \ref{tbl:auswertung} sind die Auswertungen von Video 1, Video 2 und Video 3 zu sehen, die als Eingabe für die entwickelte Software dienten. Dabei stehen TNR für \glqq{}True Negative Rate\grqq{}, FNR für \glqq{}False Negative Rate\grqq{}, TPR für \glqq{}True Positive Rate\grqq{}, FPR für \glqq{}False Positive Rate\grqq{} und ACC für \glqq{}Accuracy\grqq{}.\\
Die Ergebnisse des Programm werden in Abbildung \ref{fig:result} dargestellt. Das Programm kann eine Person am Tag und in der Nacht erkennen (Siehe Abbildungen \ref{fig:result}a, \ref{fig:result}b). Außerdem kann die Kamera in verschiedenen Positionen im Raum aufgestellt werden. Das beeinflusst die Erkennung von außergewöhnlichen Situationen nicht (Siehe Abbildungen \ref{fig:result}c, \ref{fig:result}d). Weiterhin spielt die Körpergröße eine Person keine Rolle (Siehe Abbildungen \ref{fig:result}e, \ref{fig:result}f). In Abbildung \ref{fig:result}g lag die Person auf dem Boden und ein Alarm wird ausgelöst. In der Abbildung \ref{fig:result}h lag die Person auf einem Sofa und das Programm hat die Situation als normalen Fall erkannt.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/result.pdf}
	\caption{Ergebnisse des Programms.} 
	\label{fig:result}
\end{figure}