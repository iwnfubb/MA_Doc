	\chapter{Grundlagen}\label{chp:Grundlageb}
Im diesen Kapitel werden die theoretischen Grundlagen, die diese Masterarbeit einsetzt beschrieben. Zu Beginn wird ein detaillierter Überblick über das Hintergrundsubtraktion-Verfahren gegeben. Anschließend wird die Histogrammanalyse zur Erkennung der Körperhaltung im Detail erläutert. Im Abschnitt 2.3 wird die Fuzzylogik im Detail erläutert und wie diese einzusetzen ist. 
Weiter wird das OpenCV Framework, das für moderne Computer Vision entwickelt wurde, kurz beschrieben. Zuletzt wird auf die verwendete 360° Kamera eingegangen und gezeigt, wie diese zu verwenden ist.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hintergrundsubtraktion}\label{sec:grunglagen_hintergrundsub}
Hintergrundsubtraktion ist eine häufige verwendete Technik, die statische Kameras  unter verwendet, um ein sich bewegtes Objekt aus dem Hintergrund zu extrahieren.  Hintergrundsubtraktion erzeugt eine Binärbild, das die Pixel enthält, die zu sich bewegenden Objekten in der Szene gehören. Wie der Name andeutet, werden die Vordergrundmaske durch die Hintergrundsubtraktion berechnet, was eine absolute Subtraktion zwischen dem aktuellen Bild und einem Hintergrundmodell durchführt. Der statische Teil der Szene oder allgemeiner alles, was angesichts der Merkmale der beobachtete Szene als Hintergrund betrachtet werden kann, enthalten ist.\\
In der Arbeit \cite{benezeth2010comparative} wird eine vergleichende Studie verschiedener Hintergrundsubtraktionsverfahren nach dem Stand der Technik präsentiert. Dieses Verfahren wurde seit den 1990er umfassend untersucht und hauptsächlich für Videoüberwachungsanwendungen, da sie zuerst Personen, Fahrzeuge, Tiere usw. erkennen müssen, bevor komplexere Prozesse zur Einbruchserkennung, Verfolgung, Personenzählung \cite{aziz2011pedestrian} usw. ausgeführt werden. Viele Algorithmen wurden entworfen, um die Vordergrundobjekte vom Hintergrund einer Sequenz zu segmentieren und teilen im Allgemeinen das gleiche Schema \cite{sobral2014comprehensive}:
\begin{itemize}
	\item \textbf{Initialisierung des Hintergrundes}: Ein Hintergrundmodell wird zuerst dank einer festen Anzahl von Bildern aufgebaut. Es gibt verschiedene Arten, auf die dieses Modell entworfen werden kann (statistisch, Fuzzy...).
	\item \textbf{Erkennung des Vordergrundes}: In den nächsten neu hinzugefügten Bildern wird das aktuelles Bild mit dem Hintergrundmodell verglichen. Diese Subtraktion führt zur Berechnung des Vordergrundes der Szene.
	\item \textbf{Aktualisierung des Hintergrundes}: Während dieses Prozesses erfasst wird, werden auch Bilder analysiert, um das im ersten Schritt gelernte Hintergrundmodell mit einer Lernrate zu aktualisieren. Ein Objekt, das sich nicht lange bewegt, sollte im Hintergrund integriert bleiben.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/BS_Example.pdf}
	\caption{Ein Beispiel für Hintergrundsubtraktion }
	\label{fig:BS_Example}
\end{figure}
Im nächsten Teil werden verschiedene häufige Verfahren beschrieben, um dies Verfahren genauer zu verstehen, wie die Hintergrundsubtraktion funktionieren soll.
\subsection{Adaptive Gaußschen Mixture Modell}
In \cite{kaewtrakulpong2002improved} ist ein entwickeltes Hintergrundmodell auf der Grundlage der Gaußschen Mischung präsentiert. Diese Methode ist ein gängiges Verfahren zur Hintergrundsubtraktion. Es verwendet eine selektive Aktualisierungsmethode, um jeden Hintergrundpixel durch eine Mischung von K-Gaußschen Verteilung (normalerweise K = 3 oder 5) zu modellieren \cite{kaewtrakulpong2002improved}. Verschiedene Gaußschen-Mischung stellt verschiedene Farben dar und die Gewichte der Gaußschen-Mischung stellen die Zeitanteile, die diese Farbe in der Szene verbleiben, dar. Die Pixel, die länger und statischer bleiben, sind die wahrscheinlichen Hintergrundfarben. Jeder neue Pixel wird mit vorhandenen Modellkomponenten überprüft, ob der Pixelwert ein statische Farbe ist. Die erste Gaußschen-Komponente, die mit dem neuen Pixel passt, wird aktualisiert. Wenn es keine passende Gaußschen-Komponente gibt, wird eine neue Komponente mit dem Mittelwert an diesem Punkt, einer großen Kovarianz-Matrix und einem kleinen Gewicht hinzugefügt. \\
Jeder Pixel in der Szene wird durch eine Mischung von K-Gaußschen Verteilung modelliert. Die Wahrscheinlichkeit, dass ein bestimmter Pixel zum Zeitpunkt $n$ einen Wert von $\mathrm{x}_{n}$ hat, kann wie folgt geschrieben werden:\\
\begin{equation}
p(\mathrm{x}_{n}) = \sum \limits_{j=1}^K w_j \eta(\mathrm{x}_{n};\theta_j)
\end{equation}
wobei $w_k$ Gewichtsparameter der k-ten Gauß-Komponente ist. $\eta(\mathrm{x}_{n};\theta_j)$ ist die Normalverteilung der k-ten Komponente, die wie folgt dargestellt wird \cite{kaewtrakulpong2002improved}:\\
\begin{equation}
\eta(\mathrm{x};\theta_j) = \eta(x;\mu_k, \Sigma_k) = \frac{1}{(2\pi)^\frac{D}{2} |\Sigma_k|^\frac{1}{2}} \mathrm{e}^{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^{-1}(x-\mu_k)}
\end{equation}
wobei $\mu_k$ der Durchschnitt ist. Außerdem ist $\Sigma_k =  \sigma^2_k I$ die Kovarianz der k-ten Komponente \cite{kaewtrakulpong2002improved}. Die K-Verteilungen sind auf der Grundlage des Fitnesswerts $\frac{w_k}{\sigma_k}$ geordnet und die ersten $B$-Verteilungen werden als ein Modell des Hintergrundes der Szene verwendet, wo $B$ wie folgt beschrieben werden:\\
\begin{equation}
B = \underset{b}{\arg\min}(\sum \limits_{j=1}^b w_j > T) 
\end{equation}
Der Schwellwert $T$ ist der Mindestanteil des Hintergrundmodells und stellt die kleinste Wahrscheinlichkeit dar, sodass der Hintergrund in der Szene bleibt. Die Hintergrundsubtraktion in \cite{kaewtrakulpong2002improved} wird durchgeführt, indem ein Vordergrundpixel jeden Pixel, der mehr als 2,5 Standardabweichungen von irgendeiner der B-Verteilung entfernt ist, markiert wird. Die erste Gauß-Komponente, die die oben genannte Bedingung erfüllt, wird durch die folgenden Aktualisierungsgleichungen aktualisiert \cite{kaewtrakulpong2002improved}:
\begin{eqnarray}
\hat{w}^{N+1}_k &=& (1-\alpha) \hat{w}^{N}_k + \alpha \hat{p} (w_k | \mathrm{x}_{N+1}) \\
\hat{\mu}^{N+1}_k &=& (1-\alpha) \hat{\mu}^N_k + \rho\mathrm{x}_{N+1} \\
\hat{\Sigma}^{N+1}_k &=& (1-\alpha)\hat{\Sigma}^N_k + \rho(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)^T\\
\rho &=& \alpha\eta(\mathrm{x}_{N+1};\hat{\mu}^N_k; \hat{\Sigma}^N_k)\\
 X&=&\left\{\begin{array}{@{}ll@{}}
0, & \text{wenn}\ w_k\ \text{erste Gauß-Komponente ist} \\
1, & \text{sonst}
\end{array}\right.
\end{eqnarray}
wobei $w_k$ die k-te Gaußschen Komponente ist und $\frac{1}{\alpha}$ definiert die Zeitkonstante, die die Änderung bestimmt. Wenn keine der K-Verteilungen mit diesem Pixelwert zusammenpasst, wird die unwahrscheinliche Komponente durch eine Verteilung mit dem aktuellen Wert als Mittelwert, einer großen Kovarianz-Matrix und einem kleinen Gewicht ersetzt \cite{kaewtrakulpong2002improved}.
t\subsection{Kernel Density Estimation}
Ein Nachteil von \acs{GMM} ist: Dieses Modell kann keine empfindliche Detektion erreichen, wenn der Hintergrund sehr hohe Frequenzvariation aufweist. Dieser Nachteil kann mit \acs{KDE} Modell, das in \cite{elgammal2000non} beschrieben wurde, gelöst werden.\\
Sei $x_1, x_2,..., x_n$ eine aktuelle Stichprobe von Intensitätswerten für einen Pixel. Unter Verwendung dieser Stichprobe kann die Dichtefunktion von Wahrscheinlichkeit, dass dieser Pixel einen Intensitätswert $x_t$ in Zeit $t$ haben wird, unter Verwendung des Kernschätzers $K$ als nicht-parametrisch geschätzt werden \cite{elgammal2000non}.
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^N K (x_t - x_i) 
\end{equation}
Wenn die Kernschätzfunktion $K$ als Normalfunktion $N (0;\sigma)$ wobei $\sigma$ die Kernfunktionsbandbreite ist, gewählt wird. Wenn verschiedene Farbkanäle mit unterschiedlichen Kernel-Bandbreite $\sigma^2_j$ für den j-ten Farbkanal:

\begin{gather}
\sigma
=
\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \sigma^2_2 & 0 \\
0 & 0 & \sigma^2_3 \\
\end{pmatrix}
\end{gather}

dann wird die Dichtefunktion wie folgt beschrieben:
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^N \prod \limits_{j=1}^d \frac{1}{\sqrt{2\pi\sigma^2_j}} \mathrm{e} ^ {-\frac{1}{2} \frac{({x_t}_j - {x_i}_j)^2}{\sigma^2_j}}
\end{equation}
Bei  $P(x_t)<T$ Wahrscheinlichkeitsschätzung wird der Pixel als ein Vordergrundpixel betrachtet. In diesem Fall ist $T$ ein globaler Schwellenwert über das gesamte Bild. $T$ kann so eingestellt, dass ein minimaler Prozentsatz von falschen Erkennungen erreicht wird.\\
Angenommen ist $m$ Median von $|x_i - x_{i+1}|$ für jedes Paar $(x_i, x_{i+1})$ in der Stichprobe. Nach \cite{elgammal2000non} wird die Standardabweichung der ersten Verteilung wie folgt geschätzt: 
\begin{equation}
\sigma = \frac{m}{0,68 \sqrt{2}}
\end{equation}
Bei \acs{KDE} gibt es zwei Alternative für die Aktualisierung des Hintergrundes bzw. durch ``Selective Update"\ und ``Blind Update". Die erste Alternative fügt neue Stichprobe in das Modell hinzu, wenn es als Hintergrund klassifiziert ist. Die zweite Alternative fügt einfach neue Stichproben in das Modell hinzu, egal ob sie zum Hintergrund oder Vordergrund gehören. Im Allgemeinen funktioniert \acs{KDE} im Freien bzw. nicht in Gebäuden besser als die \acs{GMM} Methode.

\subsection{K-nächster Nachbar}
Diese Methode ist eine Verbesserung von \acs{KDE} und konkret in \cite{zivkovic2006efficient} als K-NN genannt. Feste Kerngröße $D$ in \acs{KDE} wird für jeden neuen Punkt $x_i$ angepasst. Anstatt Optimierung der Größe $D$ erhöht die Anpassung $D$, solang eine feste Menge von Daten $k$ abgedeckt ist. Auf diesem Weg befinden sich große Kerne in den Gebieten mit einer kleinen Anzahl von Stichproben und kleinere Kerne in den dicht besiedelten Gebieten. Dennoch steht die Schätzung in Beziehung mit der k-NN-Klassifikation. In ~\cite{zivkovic2006efficient} wird ein $k = [0.1n]$ gewählt, wobei $n$ die Zeit für Anpassung von dem Modell und $[n]$ steht für Aufrunden von eine reale Zahl $n$ auf nächste natürliche Zahl.  Ein neuer Pixel $x_i$ passt zum Modell, wenn mehr als $k$ Punkte innerhalb $n$ Kernels vorhanden sind. Auf diesem Grund wird $k$ Nachbar als Schwellwert für diese Verbesserung genutzt und diese Methode wird auch als ``KNN" genannt. 

\subsection{Vibe}
In \cite{barnich2009vibe} wurde ein Verfahren beschrieben, das ersten Ansatz von zufälliger Aggregation in Hintergrundsubtraktion ist. Das Verfahren ist ``ViBe" genannt. Sei $p_t(x)$ ein Pixelwert $x$ in Zeit $t$. Bei \acs{GMM} oder \acs{KDE} Modell wird ein Pixelwert $p_t(x)$ als Hinter- oder Vordergrund klassifiziert, abhängig davon, wie der Pixel mit Dichtefunktion des Modells passt. In ``ViBe" wird aber eine Menge von Stichprobewerte als Pixelmodell benutzt. Um einen Wert $p_t(x)$ zu klassifizieren, wird der Wert mit seinen nächsten Werten in der Menge der Stichproben, in dem wie eine Kugel $S_R(p_t(x))$ mit Radius $R$ und Punkt $p_t(x)$ definiert wird. Ein Pixel ist genau dann als Background klassifiziert, wenn die Überschneidung $\sharp$ von Kugel $S_R(p_t(x))$ und Menge von Punkte ${p_1, p_2, ..., p_n}$ mehr als Schwellwert $\sharp_min$ ist (siehe Abbildung ~\ref{fig:vibe}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/vibe.pdf}
	\caption{Klassifizierung von $p_t(x)$ basiert auf Überschneidung von Kugel $S_R(p_t(x))$ mit Menge der Stichproben \cite{barnich2009vibe}.}
	\label{fig:vibe}
\end{figure}
 
Im nächsten Kapitel werden ein Vergleich von dem vier oben genannte Verfahren und meine eigene Methode beschrieben, damit Vorteile beziehungsweise Nachteile jeder Methode verdeutlicht werden.

\section{Histogrammanalyse}\label{sec:Histogrammanalyse}
Ein Histogramm eines Bild stellt die Tonwertverteilung in einem digitalen Bild graphisch dar. Ein Histogramm zeichnet die Anzahl der Pixel für jeden Tonwert auf. Bildhistogramm ist eine nützliche Werkzeuge, die für $Schwellenwertbindung$ auf dem Gebiet der Computervision angewendet werden kann. Die graphische Darstellung von Histogramm enthält Information über die Pixelverteilung als eine Funktion der Tonvariation, deswegen können sich Bildhistogramme auf Spitze und Täler analysieren lassen.\\ 
Weil eine unterschiedliche Körperhaltung ein unterschiedliches Muster von Projektionshistogramm aufweist, kann das Projektionshistogramm als eines der Merkmale verwendet werden, um unterschiedliche Körperhaltungen zu unterscheiden. Nach der Hintergrundsubtraktion wird eine Silhouette des Vordergrundes als ein Binärbild erstellt. Körperhaltungsanalyse wird auf die Silhouette angewendet, um die Ähnlichkeiten der horizontalen und vertikalen Projektionshistogramme der erkannten Silhouette und der Haupthaltungen zu berechnen. Die Normalisierung des durchschnittlichen Histogramms erfolgt durch Skalierung der Silhouette in eine vertikale Länge unter Beibehaltung des ursprünglichen Seitenverhältnisses \cite{haritaoglu1998ghost}. Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung (nämlich: Stehen, Beugen, Legen und Sitzen) wurden experimentell unter Verwendung von 4500 Silhouette von 7 verschiedenen Personen berechnet (siehe Abbildung ~\ref{fig:histogramm}).   
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/histogramm.pdf}
	\caption{Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung \cite{haritaoglu1998ghost}.}
	\label{fig:histogramm}
\end{figure}

Diese Methode wird verwendet, um die Ähnlichkeit der gegebenen Körperhaltung mit einer der vier Haupthaltungen zu bestimmen. Die erstellte Silhouette durch Hintergrundsubtraktion wird mit den durchschnittlichen Projektionshistogrammen  verglichen, wobei die Summe der absoluten Differenz verwendet wird, um die ähnlichste Körperhaltung zu schätzen. Angenommen ist $S_i$ die Ähnlichkeit zwischen der erkannter Silhouette und i-ten Hauptkörper. Seien $H_i$ und $V_i$ die horizontalen und vertikalen durchschnittlichen Projektionshistogrammen , $P$ und $R$ die horizontalen und vertikalen Histogramme der erkannten Silhouette. $S_i$ wird wie folgt berechnet: 
\begin{equation}\label{eq:loglikelyhood}
S_i = -\log(\sum \limits_{h}^{128} \sum \limits_{v}^{128} |H_h^i - P_h| + |V_v^i - R_v|) 
\end{equation}
Die Körperhaltung, die das höchste Ähnlichkeitsmaß ergibt, wird als geschätzte Haltung genommen.  

\section{Fuzzylogik}\label{sec:fuzzylogik}
Mit Hilfe von Hintergrundsubtraktion und Histogrammanalyse wird erstmal nur eine sich bewegte Person erkannt, aber zum Unterschied zwischen täglichen Bewegungen und ungewöhnlichen Situationen kommt Fuzzylogik zum Einsatz. In Jahr 1971 wurde die erste Forschung über Fuzzy-Algebra beschrieben ~\cite{rosenfeld1971fuzzy}.\\
Nun stellt sich die Frage, warum Fuzzylogik in diesem Fall angewendet. Es gibt mehre Gründe für Benutzung der Fuzzylogik. Erster Grund ist, dass ein Fuzzysystem einfach kreiert, das mit jedem Satz von Eingabe-Ausgabe-Daten übereinstimmen. Außerdem sind die mathematischen Konzepte hinter dem Fuzzy-Denken sehr einfach und die Vorteile, die Fuzzylogik bringt, sind enorm und zuverlässig.\\
 Fuzzylogik geht um eine unscharfe logische Menge, wobei eine Fuzzymenge seinen Mitgliedern ermöglicht, Mitgliedschaftsgrade zu haben. Wenn der Wert 1 an Objekten zugewiesen ist, die vollständig innerhalb der Menge liegen und Objekten außerhalb der Menge eine 0 zugewiesen wird, hat jedes Objekt, das teilweise in der Menge ist, einen Wert zwischen 0 und 1. Der Prozess der Fuzzylogik wird wie folgt erläutert ~\cite{dingle2011artificial}:
\begin{itemize}
\item Zuerst wird eine scharfe Menge von Eingabedaten gesammelt und unter Verwendung von Zugehörigkeitsfunktionen in einen Fuzzymenge umgewandelt. In diesem Schritt wird ein Zuordnung zwischen jedem scharfen Wert der Eingaben und einer Fuzzy-Menge wie folgt erstellt ~\cite{cingolanijfuzzylogic}:\\
$A' = F(x_0)$\\
wobei $x_0$ ein scharfen Wert der Eingabe ist, $A'$ ist Fuzzymenge mit Mitgliederfunktion $F$. $F$ kann Sinus-, Kosinus-, Sigmoid-, Gaußschen-, glockenförmige Funktion sein. 

\item  Eine Schlussfolgerung wird basierend auf ein oder mehre ($IF-THEN$) Regeln getroffen und die Regeln werden wie folgt beschrieben:\\
\textit{If X is A then Y is B}\\
\textit{Und wenn X A' ist, ergibt sich Y is B'}\\
Wobei $X$ und $Y$ linguistische Variablen (Siehe Algorithmus \ref{algo:fuzzy}) sind. $A$ und $B$ sind Fuzzymenge, $B'$ ist Ausgabe der Fuzzymenge. In diesem Schritt erhält das Fuzzysystem zunächst den Übereinstimmungsgrad jeder Regeln durch Anwendung eines konjunktiven Operators (AND- oder OR-Operator). Danach werden die Fuzzy-Sätze durch einen Fuzzy-Implikationsoperator (normalerweise Minimum oder Produkt) abgeleitet. Eine gleiche Anzahl von Ausgabesätze wie in den vordefinierten Regeln wird in dieser Stelle erzeugt und am Ende werden diese Gruppen von Ausgabe durch einen Aggregationsoperator (Maximum, Summe, normalisierte Summe, OR-Wahrscheinlichkeit) aggregiert. 
\item  Schließlich wird die Fuzzy-Ausgabe unter Verwendung der Zugehörigkeitsfunktionen in dem Defuzzifizierungsschritt auf eine scharfe Ausgabe abgebildet. Wert für jede Variable wird mithilfe der ausgewählten Defuzzifizierungsmethode berechnet, die wie folgt lautet kann ~\cite{dingle2011artificial}:\\
Schwerpunkt: $\frac{\int x \mu (x) dx}{\int \mu (x) dx}$\\
Schwerpunkt Singleton: $\frac{\sum_{i}x_i\mu_i}{\sum_{i}\mu_i}$\\
Zentrum der Region: $u|\int_{u}^{\infty} \mu(x) dx$\\
Rechtest Maximum: $argmax_x [\mu (x) = max (\mu(x))]$\\
Linkst Maximum: $argmin_x [\mu (x) = max (\mu(x))]$\\
Durchschnittliches Maximum: $mean(x) [\mu (x) = max (\mu(x))]$\\
\end{itemize}
Die Abbildung  \ref{fig:Fuzzy_Example} stellt diese drei Schritte von Fuzzylogik im graphische Bilder dar, um den Prozess einfache zu verstehen. Beispielweise gibt es ein Smart-Thermostat in einem Raum und der Thermostat soll sich an der Raumtemperatur anpassen. Eine Fuzzylogik wird erstellt, wobei die Temperatur Eingabe ist und Einstellung des Thermostates ist Ausgabe (siehe Abbildung ~\ref{fig:Fuzzy_Example}) und der Regel wird wie in Algorithmus ~\ref{algo:fuzzy} definiert. Die Temperatur wird als ``Low, Medium und High"\ klassifiziert. Wenn die Temperatur von $0$ bis  $20$ Grad ist, wird sie als ``Low"\ , von $10$ bis $20$ Grad als ``Medium"\ und von $20$ bis $40$ Grad als ``High"\ genannt. Bei Einstellung von Thermostat wird von $1$ bis $2$ als ``Low"\ , von $1$ bis $4$ als ``Medium"\ und von $3$ nach $5$ als ``High"\ definiert. Zum Beispiel ist unsere Eingabe von Temperatur ist $23$ Grad und die befindet sich zwischen ``Medium"\ und ``High"\ wie in Abbildung  ~\ref{fig:Fuzzy_Example}. Bei $23$ Grad beträgt Mitgliedschaftsgrad  $0.7$ von ``Medium"\ und $0.3$ von ``High"\ Temperatur. Nach dem Regel in Algorithmus ~\ref{algo:fuzzy} wird die Einstellung von dem Thermostat zwischen ``Low"\ und ``Medium"\ berechnet und mit dem Methode ``Schwerpunkt"\ soll die Einstellung von dem Thermostat bei $2.15$ liegen.\\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/fuzzy.png}
	\caption{Ein Beispiel für Fuzzylogik in drei Schritte. Oben: Die Temperatur von $23$ Grad wird durch Mitgliederfunktion abgebildete. Mitte: Durch die (IF-ELSE) Regel in Algorithmus \ref{algo:fuzzy} wird Ausgabe als Fuzzymenge berechnet. Unten: Ein Schwerpunkt von der gerechneten Ausgabe wird in scharfe Ausgabe abgebildet und es ergibt sich 2.15 Grad für den Thermostat.} 
	\label{fig:Fuzzy_Example}
\end{figure}
\begin{algorithm}[H]
\caption{Regel für Raumtemperatur und Einstellung des Thermostates.	}
\label{algo:fuzzy}
\If{temperature IS low}{thermostat IS high;}
\If{temperature IS medium}{thermostat IS medium;}
\If{temperature IS high}{thermostat IS low;}
\end{algorithm}
  

\section{OpenCV Framework}\label{sec:OpenCV}
OpenCV steht für Open-Computer-Vision. Die Bibliothek wird in C und C++ programmiert und kann unter Linux, Windows, MacOS laufen. OpenCV ist auch auf Schnittstelle für Java, Python, Ruby, Mathlab... entwickelt. OpenCV wurde für Recheneffizienz und mit einem starken Fokus auf Echtzeitanwendungen entwickelt. Diese Bibliothek enthält über 500 Funktionen, die viele Bereiche in der Vision einschließlich Bildverarbeitung, maschinelles Lernen, neuronale Netze... umfassen ~\cite{bradski2008learning}. OpenCV vereinfacht den Bildverarbeitungsprozess mit vielen hilfreichen vordefinierten Funktionen. Da die Arbeit um ein Echtzeitanwendung zur Erkennung der abnormalen Situationen geht und es ist nötig, die Verarbeitungszeit schnell wie möglich zu laufen, deswegen wird OpenCV in diesem Projekt benutzt.  

\section{Bosch Innenkamera}
Ziel dieser Arbeit ist Erstellung einer Anwendung, die mit der Bosch Innen Kamera funktioniert. Die Testvideos wurden mit eine Bosch Innenkamera aufgenommen. Die Bosch 360 Innenkamera kann in jede Richtung drehen und schauen. Die Kamera besteht aus Bewegungssensoren, eine Gegensprechanlage für Zwei-Wege-Audio und Infrarot-Nachtsicht, so dass Sie zu jeder Zeit über Ihr Haus schauen können. Wenn es etwas wahrnimmt, zeichnet es HD-Material auf dem lokalen Speicher auf und Sie können mit Ihrem Telefon Clips oder Live-Filmmaterial ansehen.  Mit Hilfe von dieser Kamera kann man sich fern um die Alten oder Kinder kümmern. Außerdem kann die Innenkamera eine Push-Nachrichten ans Smartphone via eine kostenlose App schicken. Einfachsten Einrichtungsschritte hilft dem Benutzer schnell wie möglich die Kamera mit IP-Verbindung starten. Mit ein paar leichten Koppeln auf dem Kopf wird die Kamera sich in die Gehäuse versenkt, oder aus der Gehäuse ausdreht. Dank integrierten Bewegungsmeldern kann die Kamera eine Bewegung verfolgen und in die Richtung von der entdeckten Bewegung drehen. Das hilft meiner Arbeit bei Lokalisierung einem Personen im Raum. Die Kamera hat zwei Vorteile, die hier gut für diese Arbeit anwendet werden kann, nämlich die Fähigkeit, jede Richtung zu drehen und Infrarot-Nachtsicht aufzunehmen. Das bedeutet, es ist ermöglicht, die Person Tag und Nacht zu betrachten und die außergewöhnliche Situation genau pünktlich zu erkennen. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{fig/BoschInnenkamera.jpg}
	\caption{Bosch 360 Grad Kamera (Quelle: www.bosch-smarthome.com) } 
	\label{fig:BoschInnenCam}
\end{figure}