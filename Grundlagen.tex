	\chapter{Grundlagen}\label{chp:Grundlageb}
Im diesen Kapitel werden die theoretischen Grundlagen, die diese Masterarbeit einsetzt beschrieben. Zu Beginn wird ein detaillierter Überblick über das Hintergrundsubtraktion-Verfahren gegeben. Anschließend wird die Histogrammanalyse zur Erkennung der Körperhaltung im Detail erläutert. Im Abschnitt 2.3 wird die Fuzzylogik im Detail erläutert und wie diese einzusetzen ist. 
Weiter wird das OpenCV Framework, das für moderne Computer Vision entwickelt wurde, kurz beschrieben. Zuletzt wird auf die verwendete 360° Kamera eingegangen und gezeigt, wie diese zu verwenden ist.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hintergrundsubtraktion}\label{sec:grunglagen_hintergrundsub}
Das Hintergrundsubtraktionsverfahren ist eine häufig verwendete Technik, die statische Kameras verwendet, um ein sich bewegtes Objekt aus dem Hintergrund zu extrahieren. Die Hintergrundsubtraktion erzeugt eine Binärbild, das die Pixel enthält, die zu den bewegenden Objekten in der Szene gehören. Wie der Name andeutet, wird die Vordergrundmaske durch die Hintergrundsubtraktion berechnet, was eine absolute Subtraktion zwischen dem aktuellen Bild und einem Hintergrundmodell durchführt. Der statische Teil der Szene oder allgemeiner alles, ist der, was angesichts der Merkmale der beobachteten Szene als Hintergrund betrachtet werden kann, enthalten ist.\\
In der Arbeit \cite{benezeth2010comparative} wird eine vergleichende Studie verschiedener Hintergrundsubtraktionsverfahren nach dem Stand der Technik präsentiert. Dieses Verfahren wurde seit den 1990er umfassend untersucht und hauptsächlich für Videoüberwachungsanwendungen verwendet, da es zuerst Personen, Fahrzeuge, Tiere usw. erkennt, bevor komplexere Prozesse zur Einbruchserkennung, Verfolgung, Personenzählung \cite{aziz2011pedestrian}, usw. angewandt werden können. Viele Algorithmen wurden entworfen, um die Vordergrundobjekte vom Hintergrund einer Sequenz zu segmentieren und teilen im Allgemeinen das gleiche Prinzip wie bei \cite{sobral2014comprehensive}:
\begin{itemize}
	\item \textbf{Initialisierung des Hintergrundes}: Das Hintergrundmodell wird zuerst nach einer festen Anzahl von Bildern aufgebaut. Es gibt verschiedene Methoden, wie dieses Modell aufgebaut werden kann z.B.: statistisch, Fuzzy.. .
	\item \textbf{Erkennung des Vordergrundes}: Das neu aufgenommene Bild wird mit dem Hintergrundmodell absolut subtrahiert. Diese Subtraktion führt zur Berechnung des Vordergrundes der Szene, wodurch ein Binärbild entsteht. Weiße Pixel im Binärbild definieren den Vordergrund der Szene und schwarze Pixel den Hintergrund.
	\item \textbf{Aktualisierung des Hintergrundmodells}: Wenn sich ein Objekt nicht mehr bewegt, soll es in den Hintergrund integriert werden. Das geschieht durch den ständigen Vergleich des aktuellen Bildes mit dem Hintergrundmodell.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/BS_Example.pdf}
	\caption{Ein Beispiel für die Hintergrundsubtraktion }
	\label{fig:BS_Example}
\end{figure}
Im nächsten Teil werden die häufig eingesetzte Techniken beschrieben, um eine Hintergrundsubtraktion durchzuführen.
\subsection{Adaptive Gaußschen Mixture Modell}
Die wissenschaftliche Arbeit \cite{kaewtrakulpong2002improved} entwickelte ein Hintergrundmodell auf Grundlage der Gaußschen Mischung. Diese Methode ist ein gängiges Verfahren zur Hintergrundsubtraktion. Es verwendet eine selektive Aktualisierungsmethode, um jeden Hintergrundpixel durch eine Mischung von K-Gaußschen Verteilungen (üblicherweise für K = 3 oder K = 5) zu modellieren \cite{kaewtrakulpong2002improved}. Verschiedene Gaußschen-Mischungen stellen die verschiedenen Farben dar. Die Gewichte der Gaußschen-Mischung repräsentieren die Zeitanteile einer Farbe in der Szene. Die Pixel, die länger unverändert bleiben, sind die wahrscheinlichen Hintergrundfarben. Jeder neue Pixel wird mit vorhandenen Modellkomponenten überprüft, ob der Pixelwert eine unveränderte Farbe darstellt. Jeder Pixel wird dann in die K-Gaußschen-Komponenten eingesetzt. Das Hintergrundmodell wird nur dann aktualisiert, falls der Pixel in eines der K-Gaußschen-Komponenten passt. Aktualisierst wird nur die Erste passende K-Gaußsche-Komponente.  Wenn es keine passende K-Gaußschen-Komponente gefunden wird, wird eine neue Komponente mit dem Pixelwert als Mittelwert gesetzt, eine große Kovarianz-Matrix und ein kleines Gewicht $w_k$ hinzugefügt. \\
Jeder Pixel in der Szene wird durch eine Mischung von K-Gaußschen Verteilungen modelliert. Die Wahrscheinlichkeit, dass ein bestimmter Pixel zum Zeitpunkt $n$ einen Wert von $\mathrm{x}_{n}$ hat, kann wie folgt beschrieben werden\cite{kaewtrakulpong2002improved}:\\
\begin{equation}
p(\mathrm{x}_{n}) = \sum \limits_{j=1}^K w_j \eta(\mathrm{x}_{n};\theta_j)
\end{equation}
wobei $w_j$ der Gewichtsparameter der k-ten Gauß-Komponente ist. $\eta(\mathrm{x}_{n};\theta_j)$ ist die Normalverteilung der k-ten Komponente, die wie folgt dargestellt wird \cite{kaewtrakulpong2002improved}:\\
\begin{equation}
\eta(\mathrm{x};\theta_j) = \eta(x;\mu_k, \Sigma_k) = \frac{1}{(2\pi)^\frac{D}{2} |\Sigma_k|^\frac{1}{2}} \mathrm{e}^{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^{-1}(x-\mu_k)}
\end{equation}
wobei $\mu_k$ der Mittelwert ist. Außerdem ist $\Sigma_k =  \sigma^2_k I$ die Kovarianz der k-ten Komponente \cite{kaewtrakulpong2002improved}. Die K-Verteilungen sind auf der Grundlage des Fitnesswerts $\frac{w_k}{\sigma_k}$ geordnet und die ersten $B$-Verteilungen werden als ein Modell des Hintergrundes der Szene verwendet, wo $B$ wie folgt beschrieben wird\cite{kaewtrakulpong2002improved}:\\
\begin{equation}
B = \underset{b}{\arg\min}(\sum \limits_{j=1}^b w_j > T) 
\end{equation}
Der Schwellenwert $T$ ist der Mindestanteil des Hintergrundmodells und stellt die kleinste Wahrscheinlichkeit dar, sodass der Hintergrund in der Szene bleibt. Die Hintergrundsubtraktion in \cite{kaewtrakulpong2002improved} wird durchgeführt, indem die Vordergrundpixel die Pixel sind, die in einer der B-Verteilungen, eine Standardabweichung von mehr als $2,5$ aufweisen. Diese Pixel werden weiß gefärbt. Die erste Gauß-Komponente, die die oben genannte Bedingung erfüllt, wird durch die folgenden Aktualisierungsgleichungen aktualisiert \cite{kaewtrakulpong2002improved}:
\begin{eqnarray}
\hat{w}^{N+1}_k &=& (1-\alpha) \hat{w}^{N}_k + \alpha \hat{p} (w_k | \mathrm{x}_{N+1}) \\
\hat{\mu}^{N+1}_k &=& (1-\alpha) \hat{\mu}^N_k + \rho\mathrm{x}_{N+1} \\
\hat{\Sigma}^{N+1}_k &=& (1-\alpha)\hat{\Sigma}^N_k + \rho(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)^T\\
\rho &=& \alpha\eta(\mathrm{x}_{N+1};\hat{\mu}^N_k; \hat{\Sigma}^N_k)\\
 X&=&\left\{\begin{array}{@{}ll@{}}
0, & \text{wenn}\ w_k\ \text{erste Gauß-Komponente ist} \\
1, & \text{sonst}
\end{array}\right.
\end{eqnarray}
wobei $w_k$ die k-te Gaußschen Komponente ist und $\frac{1}{\alpha}$ definiert die Zeitkonstante, die die Änderung bestimmt. Wenn keine der K-Verteilungen mit diesem Pixelwert zusammenpasst, wird die unwahrscheinliche Komponente durch eine Verteilung mit dem aktuellen Wert als Mittelwert, einer großen Kovarianz-Matrix und einem kleinen Gewicht ersetzt \cite{kaewtrakulpong2002improved}.
\subsection{Kernel Density Estimation}
Ein Nachteil von \acs{GMM} ist: Dieses Modell kann keine empfindliche Detektion erreichen, wenn der Hintergrund sehr hohe Frequenzvariation aufweist. Dieser Nachteil kann mit dem \acs{KDE} Modell, das in \cite{elgammal2000non} beschrieben wurde, gelöst werden.\\
Sei $x_1, x_2,..., x_n$ eine aktuelle Stichprobe von Intensitätswerten für einen Pixel. Unter Verwendung dieser Stichprobe kann die Dichtefunktion von Wahrscheinlichkeit, dass dieser Pixel einen Intensitätswert $x_t$ in Zeit $t$ hat, unter Verwendung des Kernschätzers $K$ mit Brandbreite $D$ als nicht-parametrisch geschätzt werden \cite{elgammal2000non}.
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^n K_D (x_t - x_i) 
\end{equation}
Wenn die Kernel-Schätzfunktion $K$ als Normalfunktion $N (0;\sigma)$ gewählt wird, wobei $D$ die Kernel-Funktionsbandbreite ist und verschiedene Farbkanäle mit unterschiedlichen Kernel-Bandbreiten $\sigma^2_j$ für den j-ten Farbkanal belegt werden

\begin{gather}
D
=
\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \sigma^2_2 & 0 \\
0 & 0 & \sigma^2_3 \\
\end{pmatrix}
\end{gather}
dann wird die Dichtefunktion wie folgt beschrieben:
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^N \prod \limits_{j=1}^d \frac{1}{\sqrt{2\pi\sigma^2_j}} \mathrm{e} ^ {-\frac{1}{2} \frac{({x_t}_j - {x_i}_j)^2}{\sigma^2_j}}
\end{equation}
Bei  $P(x_t)<T$ Wahrscheinlichkeitsschätzung wird der Pixel als ein Vordergrundpixel betrachtet. In diesem Fall ist $T$ ein globaler Schwellenwert über das gesamte Bild. $T$ kann so eingestellt werden, dass nur ein minimaler Prozentsatz von fehlerhaften Erkennungen erreicht wird.\\
Angenommen ist $m$ Median von $|x_i - x_{i+1}|$ für jedes Paar $(x_i, x_{i+1})$ in der Stichprobe. Nach \cite{elgammal2000non} wird die Standardabweichung der ersten Verteilung wie folgt geschätzt: 
\begin{equation}
D = \frac{m}{0,68 \sqrt{2}}
\end{equation}
Bei \acs{KDE} gibt es zwei Alternativen für die Aktualisierung des Hintergrundes bzw. durch ``Selective Update"\ und ``Blind Update". Die erste Alternative fügt neue Stichproben in das Modell hinzu, wenn es als Hintergrund klassifiziert ist. Die zweite Alternative fügt einfach neue Stichproben in das Modell hinzu, egal ob sie zum Hintergrund oder Vordergrund gehören. Im Allgemeinen funktioniert \acs{KDE} im Freien bzw. nicht in Gebäuden, besser als die \acs{GMM} Methode.

\subsection{K-nächster Nachbar}
Diese Methode ist eine Verbesserung von der \acs{KDE} Methode und konkret in \cite{zivkovic2006efficient} als K-NN genannt. Feste Kernel-Größe $D$ in \acs{KDE} wird für jeden neuen Punkt $x_i$ angepasst. Anstatt der Optimierungen der Kernel-Größe $D$, erhöht diese Methode die Kernel-Größen $D$, solang eine feste Menge von Daten $k$ abgedeckt ist. 
Mit der K-NN-Methode befinden sich große Kernels in den Gebieten mit einer kleinen Anzahl von Stichproben und kleinere Kernels in den dicht besiedelten Gebieten. Dennoch steht die Schätzung in Beziehung mit der K-NN-Klassifikation. In ~\cite{zivkovic2006efficient} wird ein $k = [0.1n]$ gewählt, wobei $n$ die Zeit für die Anpassung von dem Modell und $[n]$ steht für das Aufrunden von eine realen Zahl $n$ auf die nächste natürliche Zahl. Ein neuer Pixel $x_i$ passt zum Modell, wenn mehr als $k$ Punkte innerhalb von $n$ Kernels vorhanden sind. Auf diesem Grund wird der $k$-te Nachbar als Schwellenwert für diese Verbesserung verwendet. 

\subsection{Vibe}
In \cite{barnich2009vibe} wurde ein Verfahren beschrieben, das der erste Ansatz von zufälliger Aggregation in der Hintergrundsubtraktion ist. Das Verfahren wird konkret ``ViBe" genannt. Sei $p_t(x)$ ein Pixelwert $x$ in der Zeit $t$. Bei \acs{GMM} oder \acs{KDE} Modell wird ein Pixelwert $p_t(x)$ als Hinter- oder Vordergrund klassifiziert, abhängig davon, wie der Pixel mit der Dichtefunktion des Modells passt. In ``ViBe" wird eine Menge von Stichprobenwerten als Pixelmodell verwendet. Um einen Wert $p_t(x)$ zu klassifizieren, wird der Wert mit seinen nächstliegenden Werten in der Menge der Stichproben verglichen, indem eine Kugel $S_R(p_t(x))$ mit Radius $R$ und Punkt $p_t(x)$ definiert wird. Ein Pixel ist genau dann als Hintergrund klassifiziert, wenn die Überschneidung $\sharp$ von der Kugel $S_R(p_t(x))$ und die Menge von Punkten ${p_1, p_2, ..., p_n}$ mehr als der Schwellenwert $\sharp\_min$ ist (siehe Abbildung ~\ref{fig:vibe}).
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/vibe.pdf}
	\caption{Die Klassifizierung von $p_t(x)$ basiert auf die Überschneidung von der Kugel $S_R(p_t(x))$ mit der Menge der Stichproben \cite{barnich2009vibe}.}
	\label{fig:vibe}
\end{figure}
Im nächsten Kapitel werden die vier oben genannte Verfahren und meine eigene Methode verglichen. Es wird auch auf die verschiedenen Vor- und Nachteile verdeutlicht.
\section{Histogrammanalyse}\label{sec:Histogrammanalyse}
Ein Histogramm eines Bilds stellt die Tonwertverteilung in einem digitalen Bild graphisch dar. Ein Bild-Histogramm zeichnet die Anzahl der Pixel für jeden Tonwert auf. Es bietet ein nützliches Werkzeug für die $Schwellenwertbindung$ auf dem Gebiet der Computervision an. Die graphische Darstellung von Histogrammen enthält Informationen über die Pixelverteilung als eine Funktion der Tonvariation, deswegen lassen sich Bild-Histogramme auf Hoch- und Tiefpunkte analysieren.\\ 
Jede unterschiedliche Körperhaltung projektiert ein unterschiedliches Muster von Histogrammen, deswegen kann das Projektions-Histogramm als eins der Eigenschaften verwendet werden, um unterschiedliche Körperhaltung zu unterscheiden. Nach der Hintergrundsubtraktion wird eine Silhouette des Vordergrundes als Binärbild erstellt. Körper-haltungsanalyse wird auf die Silhouette angewendet, um die Ähnlichkeiten der horizontalen und vertikalen Projektions-Histogramme der erkannten Silhouette und der Haupthaltungen (Stehen, Beugen, Liegen und Sitzen) zu berechnen. Die Normalisierung des durchschnittlichen Histogramms erfolgt durch die Skalierung auf 128 Pixel der Silhouette indem sowohl Höhe und Breite skaliert werden, bis beide Größen kleiner oder gleich 128 Pixel aufweisen. Dabei wird das ursprünglichen Seitenverhältnis nicht verändert. \cite{haritaoglu1998ghost}. Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung wurden experimentell unter Verwendung von $4500$ Silhouette von $7$ verschiedenen Personen berechnet (siehe Abbildung ~\ref{fig:histogramm}).   
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/histogramm.pdf}
	\caption{Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung \cite{haritaoglu1998ghost}.}
	\label{fig:histogramm}
\end{figure}
Die erstellte Silhouette durch die Hintergrundsubtraktion wird mit den durchschnittlichen Projektions-Histogrammen verglichen, wobei die Summe der absoluten Differenzen verwendet wird, um die ähnlichste Körperhaltung zu schätzen. Angenommen $S_i$ ist die Ähnlichkeit zwischen der erkannten Silhouette und der i-ten Körperhaltung. Seien $H_i$ und $V_i$ die horizontalen und vertikalen durchschnittlichen Projektions-Histogrammen. $P$ und $R$ die horizontalen und vertikalen Histogramme der erkannten Silhouette. $S_i$ wird dann wie folgt berechnet: 
\begin{equation}\label{eq:loglikelyhood}
S_i = -\log(\sum \limits_{h}^{128} \sum \limits_{v}^{128} |H_h^i - P_h| + |V_v^i - R_v|) 
\end{equation}
Die Körperhaltung, die das höchste Ähnlichkeitsmaß ergibt, wird als geschätzte Haltung genommen.  
\section{Fuzzylogik}\label{sec:fuzzylogik}
Mit Hilfe von Hintergrundsubtraktion und Histogrammanalyse wird erstmal nur eine sich bewegte Person erkannt, aber zum Unterschied zwischen täglichen Bewegungen und ungewöhnlichen Situationen kommt Fuzzylogik zum Einsatz. In Jahr 1971 wurde die erste Forschung über Fuzzy-Algebra beschrieben \cite{rosenfeld1971fuzzy}.\\
Nun stellt sich die Frage, warum Fuzzylogik in diesem Fall angewendet. Es gibt mehre Gründe für Benutzung der Fuzzylogik. Erster Grund ist, dass ein Fuzzysystem einfach kreiert, das mit jedem Satz von Eingabe-Ausgabe-Daten übereinstimmen. Außerdem sind die mathematischen Konzepte hinter dem Fuzzy-Denken sehr einfach und die Vorteile, die Fuzzylogik bringt, sind enorm und zuverlässig.\\
 Fuzzylogik geht um eine unscharfe logische Menge, wobei eine Fuzzymenge seinen Mitgliedern ermöglicht, Mitgliedschaftsgrade zu haben. Wenn der Wert 1 an Objekten zugewiesen ist, die vollständig innerhalb der Menge liegen und Objekten außerhalb der Menge eine 0 zugewiesen wird, hat jedes Objekt, das teilweise in der Menge ist, einen Wert zwischen 0 und 1. Der Prozess der Fuzzylogik wird wie folgt erläutert ~\cite{dingle2011artificial}:
\begin{itemize}
\item Zuerst wird eine scharfe Menge von Eingabedaten gesammelt und unter Verwendung von Zugehörigkeitsfunktionen in einen Fuzzymenge umgewandelt. In diesem Schritt wird ein Zuordnung zwischen jedem scharfen Wert der Eingaben und einer Fuzzy-Menge wie folgt erstellt ~\cite{cingolanijfuzzylogic}:\\
$A' = F(x_0)$\\
wobei $x_0$ ein scharfen Wert der Eingabe ist, $A'$ ist Fuzzymenge mit Mitgliederfunktion $F$. $F$ kann Sinus-, Kosinus-, Sigmoid-, Gaußschen-, glockenförmige Funktion sein. 

\item  Eine Schlussfolgerung wird basierend auf ein oder mehre ($IF-THEN$) Regeln getroffen und die Regeln werden wie folgt beschrieben:\\
\textit{If X is A then Y is B}\\
\textit{Und wenn X A' ist, ergibt sich Y is B'}\\
Wobei $X$ und $Y$ linguistische Variablen (Siehe Algorithmus \ref{algo:fuzzy}) sind. $A$ und $B$ sind Fuzzymenge, $B'$ ist Ausgabe der Fuzzymenge. In diesem Schritt erhält das Fuzzysystem zunächst den Übereinstimmungsgrad jeder Regeln durch Anwendung eines konjunktiven Operators (AND- oder OR-Operator). Danach werden die Fuzzy-Sätze durch einen Fuzzy-Implikationsoperator (normalerweise Minimum oder Produkt) abgeleitet. Eine gleiche Anzahl von Ausgabesätze wie in den vordefinierten Regeln wird in dieser Stelle erzeugt und am Ende werden diese Gruppen von Ausgabe durch einen Aggregationsoperator (Maximum, Summe, normalisierte Summe, OR-Wahrscheinlichkeit) aggregiert. 
\item  Schließlich wird die Fuzzy-Ausgabe unter Verwendung der Zugehörigkeitsfunktionen in dem Defuzzifizierungsschritt auf eine scharfe Ausgabe abgebildet. Wert für jede Variable wird mithilfe der ausgewählten Defuzzifizierungsmethode berechnet, die wie folgt lautet kann ~\cite{dingle2011artificial}:\\
Schwerpunkt: $\frac{\int x \mu (x) dx}{\int \mu (x) dx}$\\
Schwerpunkt Singleton: $\frac{\sum_{i}x_i\mu_i}{\sum_{i}\mu_i}$\\
Zentrum der Region: $u|\int_{u}^{\infty} \mu(x) dx$\\
Rechtest Maximum: $argmax_x [\mu (x) = max (\mu(x))]$\\
Linkst Maximum: $argmin_x [\mu (x) = max (\mu(x))]$\\
Durchschnittliches Maximum: $mean(x) [\mu (x) = max (\mu(x))]$\\
\end{itemize}
Die Abbildung  \ref{fig:Fuzzy_Example} stellt diese drei Schritte von Fuzzylogik im graphische Bilder dar, um den Prozess einfache zu verstehen. Beispielweise gibt es ein Smart-Thermostat in einem Raum und der Thermostat soll sich an der Raumtemperatur anpassen. Eine Fuzzylogik wird erstellt, wobei die Temperatur Eingabe ist und Einstellung des Thermostates ist Ausgabe (siehe Abbildung ~\ref{fig:Fuzzy_Example}) und der Regel wird wie in Algorithmus ~\ref{algo:fuzzy} definiert. Die Temperatur wird als ``Low, Medium und High"\ klassifiziert. Wenn die Temperatur von $0$ bis  $20$ Grad ist, wird sie als ``Low"\ , von $10$ bis $20$ Grad als ``Medium"\ und von $20$ bis $40$ Grad als ``High"\ genannt. Bei Einstellung von Thermostat wird von $1$ bis $2$ als ``Low"\ , von $1$ bis $4$ als ``Medium"\ und von $3$ nach $5$ als ``High"\ definiert. Zum Beispiel ist unsere Eingabe von Temperatur ist $23$ Grad und die befindet sich zwischen ``Medium"\ und ``High"\ wie in Abbildung  ~\ref{fig:Fuzzy_Example}. Bei $23$ Grad beträgt Mitgliedschaftsgrad  $0.7$ von ``Medium"\ und $0.3$ von ``High"\ Temperatur. Nach dem Regel in Algorithmus ~\ref{algo:fuzzy} wird die Einstellung von dem Thermostat zwischen ``Low"\ und ``Medium"\ berechnet und mit dem Methode ``Schwerpunkt"\ soll die Einstellung von dem Thermostat bei $2.15$ liegen.\\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/fuzzy.png}
	\caption{Ein Beispiel für Fuzzylogik in drei Schritte. Oben: Die Temperatur von $23$ Grad wird durch Mitgliederfunktion abgebildete. Mitte: Durch die (IF-ELSE) Regel in Algorithmus \ref{algo:fuzzy} wird Ausgabe als Fuzzymenge berechnet. Unten: Ein Schwerpunkt von der gerechneten Ausgabe wird in scharfe Ausgabe abgebildet und es ergibt sich 2.15 Grad für den Thermostat.} 
	\label{fig:Fuzzy_Example}
\end{figure}
\begin{algorithm}[H]
\caption{Regel für Raumtemperatur und Einstellung des Thermostates.	}
\label{algo:fuzzy}
\If{temperature IS low}{thermostat IS high;}
\If{temperature IS medium}{thermostat IS medium;}
\If{temperature IS high}{thermostat IS low;}
\end{algorithm}
  

\section{OpenCV Framework}\label{sec:OpenCV}
OpenCV steht für Open-Computer-Vision. Die Bibliothek wird in C und C++ programmiert und kann unter Linux, Windows, MacOS laufen. OpenCV ist auch auf Schnittstelle für Java, Python, Ruby, Mathlab... entwickelt. OpenCV wurde für Recheneffizienz und mit einem starken Fokus auf Echtzeitanwendungen entwickelt. Diese Bibliothek enthält über 500 Funktionen, die viele Bereiche in der Vision einschließlich Bildverarbeitung, maschinelles Lernen, neuronale Netze... umfassen ~\cite{bradski2008learning}. OpenCV vereinfacht den Bildverarbeitungsprozess mit vielen hilfreichen vordefinierten Funktionen. Da die Arbeit um ein Echtzeitanwendung zur Erkennung der abnormalen Situationen geht und es ist nötig, die Verarbeitungszeit schnell wie möglich zu laufen, deswegen wird OpenCV in diesem Projekt benutzt.  

\section{360° Kamera}
Ziel dieser Arbeit ist Erstellung einer Anwendung, die mit der Bosch Innen Kamera funktioniert. Die Testvideos wurden mit eine Bosch Innenkamera aufgenommen. Die Bosch 360 Innenkamera kann in jede Richtung drehen und schauen. Die Kamera besteht aus Bewegungssensoren, eine Gegensprechanlage für Zwei-Wege-Audio und Infrarot-Nachtsicht, so dass Sie zu jeder Zeit über Ihr Haus schauen können. Wenn es etwas wahrnimmt, zeichnet es HD-Material auf dem lokalen Speicher auf und Sie können mit Ihrem Telefon Clips oder Live-Filmmaterial ansehen.  Mit Hilfe von dieser Kamera kann man sich fern um die Alten oder Kinder kümmern. Außerdem kann die Innenkamera eine Push-Nachrichten ans Smartphone via eine kostenlose App schicken. Einfachsten Einrichtungsschritte hilft dem Benutzer schnell wie möglich die Kamera mit IP-Verbindung starten. Mit ein paar leichten Koppeln auf dem Kopf wird die Kamera sich in die Gehäuse versenkt, oder aus der Gehäuse ausdreht. Dank integrierten Bewegungsmeldern kann die Kamera eine Bewegung verfolgen und in die Richtung von der entdeckten Bewegung drehen. Das hilft meiner Arbeit bei Lokalisierung einem Personen im Raum. Die Kamera hat zwei Vorteile, die hier gut für diese Arbeit anwendet werden kann, nämlich die Fähigkeit, jede Richtung zu drehen und Infrarot-Nachtsicht aufzunehmen. Das bedeutet, es ist ermöglicht, die Person Tag und Nacht zu betrachten und die außergewöhnliche Situation genau pünktlich zu erkennen. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{fig/BoschInnenkamera.jpg}
	\caption{Bosch 360° Kamera (Quelle: www.bosch-smarthome.com) } 
	\label{fig:BoschInnenCam}
\end{figure}