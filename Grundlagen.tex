	\chapter{Grundlagen}\label{chp:Grundlageb}
Im diesen Kapitel werden die theoretischen Grundlagen der Masterarbeit beschrieben, die zum Verständnis der nachfolgenden Kapitel notwendig sind. Zu Beginn wird ein Überblick der Hintergrundsubtraktion gegeben und aufgezeigt, welche Besonderheiten diese Arbeit auszeichnen. An schließend wird die Histogrammanalyse zur Erkennung der Körperhaltung erläutert. Zuletzt befasst der letzte Teil sich mit einem Überblick über das wichtiges Framework OpenCV, das für moderne Computer Vision entwickelt wird. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hintergrundsubtraktion}\label{sec:grunglagen_hintergrundsub}
Die Hintergrundsubtraktion ist eine gebräuchliche und weit verwendete Technik unter Verwendung von statischen Kameras zum Erzeugen eines Binärbildes, das die Pixel enthält, die zu sich bewegenden Objekten in der Szene gehören. Wie der Name andeutet, berechnet Hintergrundsubtraktion die Vordergrundmaske, die eine Subtraktion zwischen dem aktuellen Bild und einem Hintergrundmodell durchführt, wobei der statische Teil der Szene oder allgemeiner alles, was angesichts der Merkmale der beobachtete Szene als Hintergrund betrachtet werden kann, enthalten ist.\\
In der Arbeit \cite{benezeth2010comparative} wird eine vergleichende Studie verschiedener Hintergrundsubtraktionsverfahren nach dem Stand der Technik präsentiert. Dieses Verfahren wurde seit den 1990er umfassend untersucht und hauptsächlich für Videoüberwachungsanwendungen, da sie zuerst Personen, Fahrzeuge, Tiere usw. erkennen müssen, bevor komplexere Prozesse zur Einbruchserkennung, Verfolgung, Personenzählung \cite{aziz2011pedestrian} usw. ausgeführt werden. Viele Algorithmen wurden entworfen, um die Vordergrundobjekte vom Hintergrund einer Sequenz zu segmentieren und teilen im Allgemeinen das gleiche Schema:

\begin{itemize}
	\item Initialisierung des Hintergrundes: Ein Hintergrundmodell wird zuerst dank einer festen Anzahl von Frames zu bauen. Dieses Modell kann auf verschiedene Arten entworfen werden (statistisch, Fuzzy...)
	\item Erkennung des Vordergrundes: In den nächsten Frames wird ein Vergleich zwischen dem aktuellen Frame und dem Hintergrundmodell durchgeführt. Diese Subtraktion führt zu Berechnung des Vordergrundes der Szene.
	\item Aktualisierung des Hintergrundes: Während dieses Erfassungsprozesses werden auch Bilder analysiert, um das im Initialisierungsschritt gelernte Hintergrundmodell in Bezug auf eine Lernrate zu aktualisieren. Ein Objekt, das sich nicht lange bewegt, sollte im Hintergrund integriert sein.
\end{itemize}

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.90\textwidth]{fig/BS_Example.png}
	\caption{Ein Beispiel für Hintergrundsubtraktion }
	\label{fig:BS_Example}
\end{figure}
Im nächsten Teil werden verschiedene state-of-art Verfahren beschrieben, um dies Verfahren genauer zu verstehen, wie die Hintergrundsubtraktion funktionieren soll.
\subsection{Gaußschen Mixture Modell}
In \cite{kaewtrakulpong2002improved} ist das entwickelte Hintergrundmodell auf der Grundlage der Gauß'schen Mischung präsentiert, das ein meist gebräuchliche Weg ist. Es verwendet eine Methode, um jedes Hintergrundpixel durch eine Mischung von K-Gaußschen Verteilung (normalerweise K = 3 bis 5) zu modellieren. Die Gewichte der Mischung stellen die Zeitanteile dar, die diese Farbe in der Szene verbleiben. Die wahrscheinlichen Hintergrundfarben sind diejenigen, die länger und statischer bleiben \cite{kaewtrakulpong2002improved}.\\
Jeder Pixel in der Szene wird durch eine Mischung von K-Gaußschen Verteilung modelliert. Die Wahrscheinlichkeit, dass ein bestimmter Pixel zum Zeitpunkt $N$ einen Wert von $\mathrm{x}_{n}$ hat, kann wie folgt geschrieben werden:\\
\begin{equation}
p(\mathrm{x}_{n}) = \sum \limits_{j=1}^K w_j \eta(\mathrm{x}_{n};\theta_j)
\end{equation}
wobei $w_k$ ist Gewichtsparameter der k-ten Gauß-Komponente ist. $\eta(\mathrm{x}_{n};\theta_j)$ ist die Normalverteilung der k-ten Komponente, die wie folgt dargestellt wird \cite{kaewtrakulpong2002improved}:\\
\begin{equation}
\eta(\mathrm{x};\theta_j) = \eta(x;\mu_k, \Sigma_k) = \frac{1}{(2\pi)^\frac{D}{2} |\Sigma_k|^\frac{1}{2}} \mathrm{e}^{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^{-1}(x-\mu_k)}
\end{equation}
wobei $\mu_k$ der Durchschnitt ist und $\Sigma_k =  \sigma^2_k I$ ist die Kovarianz der k-ten Komponente \cite{kaewtrakulpong2002improved}. Die K-Verteilungen sind auf der Grundlage des Fitnesswerts $\frac{w_k}{\sigma_k}$ geordnet und die ersten $B$-Verteilungen werden als ein Modell des Hintergrundes der Szene verwendet, wo $B$ wie folgt beschrieben werden:\\
\begin{equation}
B = \underset{b}{\arg\min}(\sum \limits_{j=1}^b w_j > T) 
\end{equation}
Und das Schwellwert $T$ ist Mindestanteil des Hintergrundmodells, nämlich ist $T$ das minimale Wahrscheinlichkeit, dass der Hintergrund in der Szene ist. Die Hintergrundsubtraktion wird durchgeführt, indem ein Vordergrundpixel jeden Pixel markiert wird, das mehr als 2,5 Standardabweichungen von irgendeiner der B-Verteilung  entfernt ist. Die erste Gauß-Komponente, die die oben genannte Bedingung erfüllt, wird durch die folgenden Aktualisierungsgleichungen aktualisiert \cite{kaewtrakulpong2002improved}:
\begin{eqnarray}
\hat{w}^{N+1}_k &=& (1-\alpha) \hat{w}^{N}_k + \alpha \hat{p} (w_k | \mathrm{x}_{N+1}) \\
\hat{\mu}^{N+1}_k &=& (1-\alpha) \hat{\mu}^N_k + \rho\mathrm{x}_{N+1} \\
\hat{\Sigma}^{N+1}_k &=& (1-\alpha)\hat{\Sigma}^N_k + \rho(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)^T\\
\rho &=& \alpha\eta(\mathrm{x}_{N+1};\hat{\mu}^N_k; \hat{\Sigma}^N_k)\\
 X&=&\left\{\begin{array}{@{}ll@{}}
0, & \text{wenn}\ w_k\ \text{erste Gauß-Komponente ist} \\
1, & \text{sonst}
\end{array}\right.
\end{eqnarray}
wobei $w_k$ die k-ten Gaußschen Komponente und $\frac{1}{\alpha}$ definiert die Zeitkonstante, die die Änderung bestimmt. Wenn keine der K-Verteilung mit diesem Pixelwert übereinstimmt, wird die unwahrscheinliche Komponente durch eine Verteilung mit dem aktuellen Wert als Mittelwert ersetzt.

\subsection{Adaptive Gaußschen Mixture Modell}
In \cite{zivkovic2006efficient} wurde eine interessante Erweiterung von \acs{GMM} vorgeschlagen. Normales \acs{GMM} wird mit eine bestimmte Anzahl von Gaußschen Modell, aber \acs{AGMM} wird automatisch die Anzahl der Gaußschen Variablen angepasst, die zur Modellierung eines gegebenen Pixels verwendet werden. Die Erweiterung reduziert die Speicheranforderung des Algorithmus, erhöht die Recheneffizienz und kann die Leistung verbessern, wenn der Hintergrund stark sich ändert.
\subsection{Kernel Density Estimation}
Ein Nachteil von \acs{GMM} ist, dieses Modell kann keine empfindliche Detektion erreichen, wenn der Hintergrund sehr hohe Frequenzvariation aufweist. Dieser Nachteil kann mit \acs{KDE} Modell , das in \cite{elgammal2000non} beschrieben wurde, gelöst werden.\\
Sei $x_1, x_2,..., x_n$ eine aktuelle Stichprobe von Intensitätswerten für einen Pixel. Unter Verwendung dieses Stichprobe kann die Dichtefunktion, dass dieser Pixel einen Intensitätswert $x_t$ zur Zeit $t$ haben wird, unter Verwendung des Kernschätzers $K$ als nicht-parametrisch geschätzt werden \cite{elgammal2000non}.
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^N K (x_t - x_i) 
\end{equation}
Wenn wir unsere Kernschätzfunktion $K$ als Normalfunktion $N (0;\sigma)$ wählen, wobei $\sigma$ die Kernelfunktionsbandbreite darstellt. Wenn verschiedene Farbkanäle mit unterschiedlichen Kernel-Bandbreite $\sigma^2_j$ für den j-ten Farbkanal:

\begin{gather}
\sigma
=
\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \sigma^2_2 & 0 \\
0 & 0 & \sigma^2_3 \\
\end{pmatrix}
\end{gather}

dann wird die Dichtefunktion wie folgt geschrieben:
\begin{equation}
P(x_t) = \frac{1}{N} \sum \limits_{i=1}^N \prod \limits_{j=1}^d \frac{1}{\sqrt{2\pi\sigma^2_j}} \mathrm{e} ^ {-\frac{1}{2} \frac{({x_t}_j - {x_i}_j)^2}{\sigma^2_j}}
\end{equation}
Unter Verwendung dieser Wahrscheinlichkeitsschätzung wird der Pixel als ein Vordergrundpixel betrachtet, wenn $P(x_t)<T$, wobei $T$ ein globaler Schwellenwert über das gesamte Bild ist, der eingestellt werden kann, um einen gewünschten Prozentsatz von Falsch-Positiven zu erreichen.\\
Angenommen $m$ ist Median von $|x_i - x_{i+1}|$ für jedes Paar $(x_i, x_{i+1})$ in der Stichprobe. Nach \cite{elgammal2000non} wird die Standardabweichung der erste Verteilung wie folgt geschätzt: 
\begin{equation}
\sigma = \frac{m}{0,68 \sqrt{2}}
\end{equation}
Bei \acs{KDE} gibt es zwei Alternative für Update des Hintergrundes, nämlich ``Selective Update"\ und ``Blind Update". Die erste Alternative fügt neue Stichprobe in Modell hinzu, genau dann wenn es als Hintergrund klassifiziert ist. Die zweite Alternative fügt einfach neue Stichprobe in Modell hinzu.  Im Allgemein funktioniert \acs{KDE} draußen besser als \acs{GMM} Methode. Für meine Masterarbeit wurden mehre Methode ausprobiert, verglichen und ausgewertet, damit eine bessere Anwendung benutzt werden kann.  

\subsection{Vibe}
In \cite{barnich2009vibe} wurde ein Verfahren beschrieben, das ersten Ansatz von zufälliger Aggregation in Hintergrundsubtraktion ist. Das Verfahren ist ``ViBe" genannt. Sei $p_t(x)$ ein Pixelwert $x$ in Zeit $t$. Bei \acs{GMM} oder \acs{KDE} Modell wird ein Pixelwert $p_t(x)$ als Hinter- oder Vordergrund klassifiziert, abhängig davon, wie der Pixel mit Dichtefunktion des Modells passt. In ``ViBe" wird aber eine Menge von Stichprobewerte als Pixelmodell benutzt. Um einen Wert $p_t(x)$ zu klassifizieren, wird der Wert mit seinen nächsten Werten in der Menge der Stichproben, in dem wie eine Kugel $S_R(p_t(x))$ mit Radius $R$ und Punkt $p_t(x)$ definiert wird. Ein Pixel ist genau dann als Background klassifiziert, wenn die Überschneidung $\sharp$ von Kugel $S_R(p_t(x))$ und Menge von Punkte ${p_1,p_2, ..., p_n}$ mehr als Schwellwert $\sharp_min$ ist (siehe Abbildung ~\ref{fig:vibe}).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.3\textwidth]{fig/vibe.pdf}
	\caption{Klassifizierung von $p_t(x)$ basiert auf Überschneidung von Kugel $S_R(p_t(x))$ mit Menge der Stichproben \cite{barnich2009vibe}.}
	\label{fig:vibe}
\end{figure}
 
Im nächsten Kapitel wird ein Vergleich von dem vier oben genannte Verfahren und meine eigene Methode beschrieben.

\section{Histogrammanalyse}\label{sec:Histogrammanalyse}
Ein Histogramm eines Bildes ist graphische Darstellung der Tonwertverteilung in einem digitalen Bild. Ein Histogramm zeichnet die Anzahl der Pixel für jeden Tonwert auf. Auf dem Gebiet der Computervision können Bildhistogramme nützliche Werkzeuge für $Thresholding$ sein. Da die in dem Graphen enthaltene Information eine Darstellung der Pixelverteilung als eine Funktion der Tonvariation ist, können sich Bildhistogramme auf Spitze und Täler analysieren lassen.\\
Da eine unterschiedliche Körperhaltung ein unterschiedliches Muster von Projektionshistogramm aufweist, kann das Projektionshistogramm als eines der Merkmale verwendet werden, um unterschiedliche Körperhaltungen zu unterscheiden. Nach der Hintergrundsubtraktion wird eine Silhouette des Vordergrundes als ein Binärbild erstellt. Eine Körperhaltungsanalyse wird auf die Silhouette angewendet, um die Ähnlichkeiten der horizontalen und vertikalen Projektionshistogramme der erkannten Silhouette und der Haupthaltungen zu berechnen. Die Normalisierung des durchschnittlichen Histogramm erfolgt durch Skalierung der Silhouette in eine vertikale Länge unter Beibehaltung des ursprünglichen Seitenverhältnisses \cite{haritaoglu1998ghost}. Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung (nämlich: Stehen, Beugen, Legen und Sitzen) wurden experimentell unter Verwendung von 4500 Silhouette von 7 verschiedenen Personen berechnet (siehe Abbildung ~\ref{fig:histogramm}).   
\begin{figure}[h]
	\centering
	\includegraphics[width=1\textwidth]{fig/histogramm.pdf}
	\caption{Normalisierte horizontale und vertikale Projektionsvorlagen für jede Körperhalterung \cite{haritaoglu1998ghost}.}
	\label{fig:histogramm}
\end{figure}

Diese Methode werden verwendet, um die Ähnlichkeit der gegebenen Körperhaltung mit einer der vier Haupthaltungen zu bestimmen. Die erstellte Silhouette durch Hintergrundsubtraktion wird mit den durchschnittlichen Projektionshistogramme verglichen, wobei die Summe der absoluten Differenz verwendet wird, um die ähnlichste Körperhaltung zu schätzen. Angenommen ist $S_i$ die Ähnlichkeit zwischen der erkannter Silhouette und i-ten Hauptkörper. Seien $H_i$ und $V_i$ die horizontalen und vertikalen durchschnittlichen Projektionshistogramme, $P$ und $R$ die horizontalen und vertikalen Histogramme der erkannten Silhouette. $S_i$ wird wie folgt berechnet: 
\begin{equation}\label{eq:loglikelyhood}
S_i = -\log(\sum \limits_{h}^{128} \sum \limits_{v}^{128} |H_h^i - P_h| + |V_v^i - R_v|) 
\end{equation}
Die Körperhaltung, die das höchste Ähnlichkeitsmaß ergibt, wird als geschätzte Haltung genommen.  

\section{Fuzzylogik}\label{sec:fuzzylogik}
Mit Hilfe von Hintergrundsubtraktion und Histogrammanalyse wird erstmal nur eine sich bewegte Person erkannt, aber zum Unterschied zwischen täglichen Bewegungen und ungewöhnlichen Situationen kommt Fuzzylogik zum Einsatz. In Jahr 1971 wurde die erste Forschung über Fuzzy-Algebra beschrieben ~\cite{rosenfeld1971fuzzy}. Fuzzylogik geht um eine unscharfe logische Menge, wobei eine Fuzzymenge seinen Mitglieder ermöglicht, Mitgliedschaftsgrade zu haben. Wenn der Wert 1 an Objekten zugewiesen ist, die vollständig innerhalb der Menge liegen und Objekten außerhalb der Menge eine 0 zugewiesen wird, hat jedes Objekt, das teilweise in der Menge ist, einen Wert zwischen 0 und 1. Der Prozess der Fuzzylogik wird wie folgt erläutert ~\cite{dingle2011artificial}:
\begin{itemize}
\item Zuerst wird ein scharfer Menge von Eingabedaten gesammelt und unter Verwendung von Zugehörigkeitsfunktionen in einen Fuzzymenge umgewandelt.
\item  Eine Schlussfolgerung wird basierend auf ein oder mehre ($IF-THEN$) Regeln getroffen.
\item  Schließlich wird die Fuzzy-Ausgabe unter Verwendung der Zugehörigkeitsfunktionen in dem Defuzzifizierungsschritt auf eine scharfe Ausgabe abgebildet.
\end{itemize}

Beispielweise gibt es ein Smart-Thermostat in einem Raum und der Thermostat soll sich an der Raumtemperatur anpassen. Eine Fuzzylogik wird erstellt, wobei die Temperatur Eingabe ist und Einstellung des Thermostates is Ausgabe (siehe Abbildung ~\ref{fig:Fuzzy_Example}) und der Regel wird wie in Algorithmus ~\ref{algo:fuzzy} definiert. Die Temperatur wird als ``Low, Medium und High" klassifiziert. Wenn die Temperatur von $0$ bis  $20$ Grad ist, wird sie als ``Low" klassifiziert, von $10$ bis $20$ Grad als ``Medium" und von $20$ bis $40$ Grad als "High``.Bei Einstellung von Thermostat wird von $1$ bis $2$ als "Low`` definiert, von $1$ bis $4$ als ``Medium" und von $3$ nach $5$ als ``High". Zum Beispiel ist unsere Eingabe von Temperatur ist $23$ Grad und die befindet sich zwischen ``Medium" und ``High" wie in Abbildung  ~\ref{fig:Fuzzy_Example}. Nach dem Regel in Algorithmus ~\ref{algo:fuzzy} wird die Einstellung von dem Thermostat zwischen ``Low" und ``Medium" betrachtet und mit dem Methode ``Zentral von Gravitativ" soll die Einstellung von dem Thermostat bei $2.15$ liegen.\\
\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.8\textwidth]{fig/fuzzy.png}
	\caption{Ein Beispiel für Fuzzylogik } 
	\label{fig:Fuzzy_Example}
\end{figure}
\begin{algorithm}[htpb]
\caption{Regel für Raumtemperatur und Einstellung des Thermostates.	}
\label{algo:fuzzy}
\If{temperature IS low}{thermostat IS high;}
\If{temperature IS medium}{thermostat IS medium;}
\If{temperature IS high}{thermostat IS low;}
\end{algorithm}
  



\section{OpenCV Framework}\label{sec:OpenCV}
OpenCV ist eine Open-Source-Computer-Vision-Bibliothek, die in C und C++ programmiert wird und unter Linux, Windows, MacOS läuft. OpenCV ist auch auf Schnittstelle für Java, Python, Ruby, Mathlab... entwickelt. OpenCV wurde für Recheneffizienz und mit einem starken Fokus auf Echtzeitanwendungen entwickelt. Diese Bibliothek enthält über 500 Funktionen, die viele Bereiche in der Vision einschließlich Bildverarbeitung, maschinelles Lernen, neuronale Netze... umfassen ~\cite{bradski2008learning}. Da die Arbeit um ein Echtzeitanwendung zur Erkennung der abnormalen Situationen geht, deswegen kommt OpenCV hier zum Einsatz.  

\section{Bosch Innenkamera}
Für diese Masterarbeit wurden die Videos mit eine Bosch Innenkamera aufgenommen. Die Bosch 360 Innenkamera kann in jede Richtung drehen und schauen. Die im Innenbereich angeschlossene Kamera umfasst Bewegungssensoren, eine Gegensprechanlage für Zwei-Wege-Audio und Infrarot-Nachtsicht, so dass Sie zu jeder Zeit über Ihr Haus schauen können. Wenn es etwas wahrnimmt, zeichnet es HD-Material auf dem lokalen Speicher auf und Sie können mit Ihrem Telefon Clips oder Live-Filmmaterial ansehen.  Mit Hilfe von dieser Kamera kann man sich fern um die Alten kümmern, die allein lebenden sind.  Die Kamera hat zwei Vorteile, die hier gut für diese Arbeit anwendet werden kann, nämlich die Fähigkeit,jede Richtung zu drehen und Infrarot-Nachtsicht aufzunehmen.  

\begin{figure}[htpb]
	\centering
	\includegraphics[width=0.8\textwidth]{fig/BoschInnenkamera.jpg}
	\caption{Bosch 360 Grad Kamera (Quelle: www.bosch-smarthome.com) } 
	\label{fig:BoschInnenCam}
\end{figure}