	\chapter{Grundlagen}\label{chp:Grundlageb}
Im diesen Kapitel werden die theoretischen Grundlagen, die diese Masterarbeit einsetzt beschrieben. Zu Beginn wird ein detaillierter Überblick über das Hintergrundsubtraktion-Verfahren gegeben. Anschließend wird die Histogrammanalyse zur Erkennung der Körperhaltung im Detail erläutert. Im Abschnitt 2.3 wird die Fuzzylogik im Detail erläutert und wie diese einzusetzen ist. 
Weiter wird das OpenCV Framework, das für moderne Computer Vision entwickelt wurde, kurz beschrieben. Zuletzt wird auf die verwendete 360° Kamera eingegangen und gezeigt, wie diese zu verwenden ist.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hintergrundsubtraktion}\label{sec:grunglagen_hintergrundsub}
Das Hintergrundsubtraktionsverfahren ist eine häufig verwendete Technik, die statische Kameras verwendet, um ein sich bewegtes Objekt aus dem Hintergrund zu extrahieren. Die Hintergrundsubtraktion erzeugt eine Binärbild, das die Pixel enthält, die zu den bewegenden Objekten in der Szene gehören. Wie der Name andeutet, wird die Vordergrundmaske durch die Hintergrundsubtraktion berechnet, was eine absolute Subtraktion zwischen dem aktuellen Bild und einem Hintergrundmodell durchführt. Der statische Teil der Szene oder allgemeiner alles, ist der, was angesichts der Merkmale der beobachteten Szene als Hintergrund betrachtet werden kann, enthalten ist. Die Abbildung \ref{fig:BS_Example} stellt ein einfaches Beispiel für die Hintergrundsubtraktion. Das Ergebnis einer absoluten Subtraktion von aktuellem Bild und einem Hintergrundmodell ist ein Binärbild, indem die Bewegung einer Person mit weißen Pixel dargestellt.\\
In der Arbeit \cite{benezeth2010comparative} wird eine vergleichende Studie verschiedener Hintergrundsubtraktionsverfahren nach dem Stand der Technik präsentiert. Viele Algorithmen wurden entworfen, um die Vordergrundobjekte vom Hintergrund einer Sequenz zu segmentieren und teilen im Allgemeinen das gleiche Prinzip wie bei \cite{sobral2014comprehensive}:
\begin{itemize}
	\item \textbf{Initialisierung des Hintergrundes}: Das Hintergrundmodell wird zuerst nach einer festen Anzahl von Bildern aufgebaut. Es gibt verschiedene Methoden, wie dieses Modell aufgebaut werden kann z.B.: statistisch, Fuzzy.. .
	\item \textbf{Erkennung des Vordergrundes}: Das neu aufgenommene Bild wird mit dem Hintergrundmodell absolut subtrahiert. Diese Subtraktion führt zur Berechnung des Vordergrundes der Szene, wodurch ein Binärbild entsteht. Weiße Pixel im Binärbild definieren den Vordergrund der Szene und schwarze Pixel den Hintergrund.
	\item \textbf{Aktualisierung des Hintergrundmodells}: Während dieses Aktualisierungsprozesses werden auch Bilder analysiert, um das Hintergrundmodell im ersten Schritt in Bezug auf eine Lernrate zu aktualisieren. Die Pixel, die sich lang nicht mehr ändern, sollten zu Hintergrundpixel sein.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/BS_Example.pdf}
	\caption{Ein Beispiel für die Hintergrundsubtraktion }
	\label{fig:BS_Example}
\end{figure}
Im nächsten Teil werden die häufig eingesetzte Techniken beschrieben, um eine Hintergrundsubtraktion durchzuführen.
\subsection{Adaptive Gaußschen Mixture Modell}
Die wissenschaftliche Arbeit \cite{kaewtrakulpong2002improved} entwickelte ein Hintergrundmodell auf Grundlage der Gaußschen Mischung. Diese Methode ist ein gängiges Verfahren zur Hintergrundsubtraktion. Es verwendet eine selektive Aktualisierungsmethode, um jeden Hintergrundpixel durch eine Mischung von K-Gaußschen Verteilungen (üblicherweise für K = 3 oder K = 5) zu modellieren \cite{kaewtrakulpong2002improved}. Verschiedene Gaußschen-Mischungen stellen die verschiedenen Farben dar. Die Gewichte der Gaußschen-Mischung repräsentieren die Zeitanteile einer Farbe in der Szene. Die Pixel, die länger unverändert bleiben, sind die wahrscheinlichen Hintergrundfarben. Jeder neue Pixel wird mit vorhandenen Modellkomponenten überprüft, ob der Pixelwert eine unveränderte Farbe darstellt. Jeder Pixel wird dann in die K-Gaußschen-Komponenten eingesetzt. Das Hintergrundmodell wird nur dann aktualisiert, falls der Pixel in eines der K-Gaußschen-Komponenten passt. Aktualisierst wird nur die Erste passende K-Gaußsche-Komponente.  Wenn es keine passende K-Gaußschen-Komponente gefunden wird, wird eine neue Komponente mit dem Pixelwert als Mittelwert gesetzt, eine große Kovarianz-Matrix und ein kleines Gewicht $w_k$ hinzugefügt. \\
Jeder Pixel in der Szene wird durch eine Mischung von K-Gaußschen Verteilungen modelliert. Die Wahrscheinlichkeit, dass ein bestimmter Pixel zum Zeitpunkt $n$ einen Wert von $\mathrm{x}_{n}$ hat, kann wie folgt beschrieben werden\cite{kaewtrakulpong2002improved}:\\
\begin{equation}
p(\mathrm{x}_{n}) = \sum \limits_{j=1}^K w_j \eta(x;\mu_k, \Sigma_k)
\end{equation}
wobei $w_j$ der Gewichtsparameter der k-ten Gauß-Komponente ist. Außerdem ist $\eta(x;\mu_k, \Sigma_k)$ die Normalverteilung der k-ten Komponente, die wie folgt dargestellt wird \cite{kaewtrakulpong2002improved}:\\
\begin{equation}
\eta(x;\mu_k, \Sigma_k) = \frac{1}{(2\pi)^\frac{D}{2} |\Sigma_k|^\frac{1}{2}} \mathrm{e}^{-\frac{1}{2}(x-\mu_k)^T \Sigma_k^{-1}(x-\mu_k)}
\end{equation}
wobei $\mu_k$ der Mittelwert ist. Außerdem ist $\Sigma_k =  \sigma^2_k I$ die Kovarianz der k-ten Komponente \cite{kaewtrakulpong2002improved}. Die K-Verteilungen sind auf der Grundlage des Fitnesswerts $\frac{w_k}{\sigma_k}$ geordnet und die ersten $B$-Verteilungen werden als ein Modell des Hintergrundes der Szene verwendet, wo $B$ wie folgt beschrieben wird\cite{kaewtrakulpong2002improved}:\\
\begin{equation}
B = \underset{b}{\arg\min}(\sum \limits_{j=1}^b w_j > T) 
\end{equation}
Der Schwellenwert $T$ ist der Mindestanteil des Hintergrundmodells und stellt die kleinste Wahrscheinlichkeit dar, sodass der Hintergrund in der Szene bleibt. Die Hintergrundsubtraktion in \cite{kaewtrakulpong2002improved} wird durchgeführt, indem die Vordergrundpixel die Pixel sind, die in einer der B-Verteilungen eine Standardabweichung von mehr als $2,5$ aufweisen. Diese Pixel werden weiß gefärbt. Die erste Gaußschen-Komponente, die die Bedingung 2.3 erfüllt, wird durch die folgenden Aktualisierungsgleichungen aktualisiert \cite{kaewtrakulpong2002improved}:
\begin{eqnarray}
\hat{w}^{N+1}_k &=& (1-\alpha) \hat{w}^{N}_k + \alpha \hat{p} (\Theta_k | \mathrm{x}_{N+1}) \\
\hat{\mu}^{N+1}_k &=& (1-\alpha) \hat{\mu}^N_k + \rho\mathrm{x}_{N+1} \\
\hat{\Sigma}^{N+1}_k &=& (1-\alpha)\hat{\Sigma}^N_k + \rho(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)(\mathrm{x}_{N+1} - \hat{\mu}^{N+1}_k)^T\\
\rho &=& \alpha\eta(\mathrm{x}_{N+1};\hat{\mu}^N_k; \hat{\Sigma}^N_k)\\
 \hat{p} (\Theta_k | x_{N+1})&=&\left\{\begin{array}{@{}ll@{}}
0, & \text{wenn}\ \Theta_k\ \text{erste passende Gauß-Komponente ist} \\
1, & \text{sonst}
\end{array}\right.
\end{eqnarray}
wobei $\Theta_k$ die k-te Gaußschen Komponente ist und $\frac{1}{\alpha}$ definiert die Zeitkonstante, die die Änderung bestimmt. Der aktualisierte Gewichtsparameter wird mit $\hat{w}^{N+1}_k$ genannt und $\hat{\mu}^{N+1}_k$, $\hat{\Sigma}^{N+1}_k$ sind erneute Mittelwert und Kovarianz.
Wenn keine der K-Verteilungen mit diesem Pixelwert zusammenpasst, wird die unwahrscheinliche Komponente durch eine Verteilung mit dem aktuellen Wert als Mittelwert, einer großen Kovarianz-Matrix und einem kleinen Gewicht ersetzt \cite{kaewtrakulpong2002improved}.
\subsection{Kernel Density Estimation}
Ein Nachteil von \acs{GMM} ist: Dieses Modell kann keine empfindliche Detektion erreichen, wenn der Hintergrund sehr hohe Frequenzvariation aufweist. Dieser Nachteil kann mit einem \acs{KDE} Modell, das in \cite{elgammal2000non} beschrieben wurde, gelöst werden.\\
Sei $x_1, x_2,..., x_n$ eine aktuelle Stichprobe von Intensitätswerten für einen Pixel. Unter Verwendung dieser Stichprobe kann die Dichtefunktion von Wahrscheinlichkeit, dass dieser Pixel einen Intensitätswert $x_t$ in Zeit $t$ hat, unter Verwendung des Kernschätzers $K$ mit Brandbreite $D$ als nicht-parametrisch geschätzt werden \cite{elgammal2000non}.
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^n K_D (x_t - x_i) 
\end{equation}
Angenommen ist $D$ die Kernel-Funktionsbandbreite und verschiedene Farbkanäle werden mit unterschiedlichen Kernel-Bandbreiten $\sigma^2_j$ für den j-ten Farbkanal wie die Gleichung 2.10.

\begin{gather}
D
=
\begin{pmatrix}
\sigma^2_1 & 0 & 0 \\
0 & \sigma^2_2 & 0 \\
0 & 0 & \sigma^2_3 \\
\end{pmatrix}
\end{gather}
Wenn die Kernel-Schätzfunktion $K$ als Normalfunktion $N (0;\sigma)$ gewählt wird, wird die Dichtefunktion dann wie folgt beschrieben:
\begin{equation}
P(x_t) = \frac{1}{n} \sum \limits_{i=1}^N \prod \limits_{j=1}^d \frac{1}{\sqrt{2\pi\sigma^2_j}} \mathrm{e} ^ {-\frac{1}{2} \frac{({x_t}_j - {x_i}_j)^2}{\sigma^2_j}}
\end{equation}
Bei  $P(x_t)<T$ Wahrscheinlichkeitsschätzung wird der Pixel als ein Vordergrundpixel betrachtet. In diesem Fall ist $T$ ein globaler Schwellenwert über das gesamte Bild. $T$ kann so eingestellt werden, dass nur ein minimaler Prozentsatz von fehlerhaften Erkennungen erreicht wird.\\
Angenommen ist $m$ Median von $|x_i - x_{i+1}|$ für jedes Paar $(x_i, x_{i+1})$ in der Stichprobe. Nach \cite{elgammal2000non} wird die Standardabweichung der ersten Verteilung wie folgt geschätzt: 
\begin{equation}
D = \frac{m}{0,68 \sqrt{2}}
\end{equation}
Bei \acs{KDE} gibt es zwei Alternativen für die Aktualisierung des Hintergrundes bzw. durch \glqq{}Selective Update\grqq{} und \glqq{}Blind Update\grqq{}. Die erste Alternative fügt neue Stichproben zum Modell hinzu, wenn es als Hintergrund klassifiziert ist. Die zweite Alternative fügt einfach neue Stichproben zum Modell hinzu, egal ob sie zum Hintergrund oder Vordergrund gehören. Im Allgemeinen funktioniert \acs{KDE} im Freien bzw. nicht in Gebäuden, besser als die \acs{GMM} Methode.

\subsection{K-nächster Nachbar}
Diese Methode ist eine Verbesserung von der \acs{KDE} Methode und konkret in \cite{zivkovic2006efficient} als K-NN genannt. Bei dieser Methode wird  die feste Kerngröße $D$ in \acs{KDE} für jeden neuen Punkt $x_i$ angepasst. Anstatt der Optimierungen der Kerngröße $D$, erhöht diese Methode die Kerngrößen $D$, solang eine feste Menge von Daten $k$ abgedeckt ist. 
Mit der K-NN-Methode befinden sich große Kerne in den Gebieten mit einer kleinen Anzahl von Stichproben und kleinere Kerne in den dicht besiedelten Gebieten. In ~\cite{zivkovic2006efficient} wird ein $k = [0.1n]$ gewählt, wobei $n$ die Zeit für die Anpassung des Modells ist und $[n]$ für das Aufrunden einer realen Zahl $n$ auf die nächste natürliche Zahl steht. Ein neuer Pixel $x_i$ passt zum Modell, wenn mehr als $k$ Punkte innerhalb von $n$ Kernen vorhanden sind. Auf diesem Grund wird der $k$-te Nachbar als Schwellenwert für diese Verbesserung verwendet. 

\subsection{Vibe}
In \cite{barnich2009vibe} wird ein Verfahren beschrieben, welches eine zufällige Aggregation zur der Hintergrundsubtraktion verwendet. Das Verfahren wird \glqq{}ViBe\grqq{} genannt. Sei $p_t(x)$ ein Pixelwert $x$ zur Zeit $t$. Bei einer \acs{GMM} oder \acs{KDE} Modell wird ein Pixelwert $p_t(x)$ als Hinter- oder Vordergrund klassifiziert, abhängig davon, wie der Pixel mit der Dichtefunktion des Modells passt. In \glqq{}ViBe\grqq{} wird eine Menge von Stichprobenwerten als Pixelmodell verwendet. Um einen Wert $p_t(x)$ zu klassifizieren, wird der Wert mit seinen nächstliegenden Werten in der Menge der Stichproben verglichen, indem eine Kugel $S_R(p_t(x))$ mit Radius $R$ und Punkt $p_t(x)$ definiert wird. Ein Pixel ist genau dann als Hintergrund klassifiziert, wenn die Überschneidung $\sharp$ von der Kugel $S_R(p_t(x))$ und die Menge von Punkten ${p_1, p_2, ..., p_n}$ mehr als der Schwellenwert $\sharp_{min}$ ist (siehe Abbildung ~\ref{fig:vibe}).
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/vibe.pdf}
	\caption{Die Klassifizierung von $p_t(x)$ basiert auf die Überschneidung der Kugel $S_R(p_t(x))$ mit der Menge der Stichproben \cite{barnich2009vibe}.}
	\label{fig:vibe}
\end{figure}
Im nächsten Kapitel wird ein Vergleich von den vier oben genannten Verfahren und meine eigene Methode beschrieben. Es wird auch auf die verschiedenen Vor- und Nachteile verdeutlicht.
\section{Histogrammanalyse}\label{sec:Histogrammanalyse}
Ein Histogramm eines Bilds stellt die Tonwertverteilung in einem digitalen Bild graphisch dar. Ein Bildhistogramm zeichnet die Anzahl der Pixel für jeden Tonwert auf. Es bietet ein nützliches Werkzeug für die $Schwellenwertbindung$ auf dem Gebiet der Computervision an. Die graphische Darstellung von Histogrammen enthält Informationen über die Pixelverteilung als eine Funktion der Tonvariation, deswegen lassen sich Bild-Histogramme auf Hoch- und Tiefpunkte analysieren \cite{suttonhistograms}.\\ 
Jede unterschiedliche Körperhaltung projektiert ein unterschiedliches Muster von Histogrammen, deswegen kann das Projektions-Histogramm als eins der Eigenschaften verwendet werden, um unterschiedliche Körperhaltung zu unterscheiden. Nach der Hintergrundsubtraktion wird eine Silhouette des Vordergrundes als Binärbild erstellt. Eine Körperhaltungsanalyse wird auf die Silhouette angewendet, um die Ähnlichkeiten der horizontalen und vertikalen Projektions-Histogramme der erkannten Silhouette und der Haupthaltungen (Stehen, Beugen, Liegen und Sitzen) zu berechnen. Die Normalisierung des durchschnittlichen Histogramms erfolgt durch die Skalierung auf 128 Pixel der Silhouette indem sowohl Höhe und Breite skaliert werden, bis beide Größen kleiner oder gleich 128 Pixel aufweisen. Dabei wird das ursprünglichen Seitenverhältnis nicht verändert. \cite{haritaoglu1998ghost}. Normalisierte horizontale und vertikale Referenz-Histogramme für jede Körperhalterung wurden experimentell unter Verwendung von $4500$ Silhouette von $7$ verschiedenen Personen berechnet \cite{haritaoglu1998ghost} (siehe Abbildung ~\ref{fig:histogramm}).   
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{fig/histogramm.pdf}
	\caption{Normalisierte horizontale und vertikale Referenz-Histogramme für jede Körperhalterung \cite{haritaoglu1998ghost}.}
	\label{fig:histogramm}
\end{figure}
Die erstellte Silhouette durch die Hintergrundsubtraktion wird mit den durchschnittlichen Projektions-Histogrammen verglichen, wobei die Summe der absoluten Differenzen verwendet wird, um die ähnlichste Körperhaltung zu schätzen. Angenommen $S_i$ ist die Ähnlichkeit zwischen der erkannten Silhouette und der i-ten Körperhaltung. Seien $H_i$ und $V_i$ die horizontalen und vertikalen durchschnittlichen Projektions-Histogrammen. $P$ und $R$ die horizontalen und vertikalen Histogramme der erkannten Silhouette. $S_i$ wird dann wie folgt berechnet: 
\begin{equation}\label{eq:loglikelyhood}
S_i = -\log(\sum \limits_{h}^{128} \sum \limits_{v}^{128} |H_h^i - P_h| + |V_v^i - R_v|) 
\end{equation}
Die Körperhaltung, die das höchste Ähnlichkeitsmaß ergibt, wird als geschätzte Haltung genommen.  
\section{Fuzzylogik}\label{sec:fuzzylogik}
Mit Hilfe von Hintergrundsubtraktion und Histogrammanalyse wird erstmal nur eine sich bewegte Person erkannt, aber zum Unterschied zwischen täglichen Bewegungen und ungewöhnlichen Situationen kommt Fuzzylogik zum Einsatz. In Jahr 1971 wurde die erste Forschung über Fuzzy-Algebra beschrieben\cite{rosenfeld1971fuzzy}.\\
Nun stellt sich die Frage, warum Fuzzylogik in diesem Fall angewendet wird. Es gibt mehre Gründe für die Benutzung der Fuzzylogik. Ein der Gründe ist, dass die mathematischen Konzepte hinter dem Fuzzy-Denken sehr einfach sind. Außerdem sind die Vorteile, die Fuzzylogik bringt, enorm und zuverlässig.\\
Fuzzylogik geht es um eine unscharfe logische Menge, die Fuzzymenge die Mitgliedern ermöglicht, Mitgliedschaftsgrade zu haben. Objekte bekommen den Wert $1$, wenn sie vollständig innerhalb der Menge liegen und Objekten außerhalb der Menge bekommen den Wert $0$. Jedes Objekt, das teilweise in der Menge ist, bekommt einen Wert zwischen 0 und 1 zugewiesen. Der Prozess der Fuzzylogik wird wie folgt erläutert ~\cite{dingle2011artificial}:
\begin{itemize}
\item Zuerst wird eine scharfe Menge von Eingabedaten gesammelt und unter Verwendung von Zugehörigkeitsfunktionen in einen Fuzzymenge umgewandelt. In diesem Schritt wird ein Zuordnung zwischen jedem scharfen Wert der Eingaben und einer Fuzzy-Menge wie folgt erstellt ~\cite{cingolanijfuzzylogic}:\\
$A' = F(x_0)$\\
wobei $x_0$ ein scharfen Wert der Eingabe ist, $A'$ ist Fuzzymenge mit Mitgliederfunktion $F$. $F$ kann eine Sinus-, Kosinus-, Sigmoid-, Gaußschen-, glockenförmige Funktion sein. 

\item  Eine Schlussfolgerung wird basierend auf einer oder mehreren ($IF-THEN$) Regeln getroffen und die Regeln werden wie folgt beschrieben:\\
\textit{If X is A then Y is B}\\
\textit{Und wenn X A' ist, ergibt sich Y is B'}\\
Wobei $X$ und $Y$ linguistische Variablen (Siehe Algorithmus \ref{algo:fuzzy}) sind. $A$ und $B$ sind Fuzzymengen, $B'$ ist Ausgabe der Fuzzymenge. In diesem Schritt erhält das Fuzzysystem zunächst den Übereinstimmungsgrad jeder Regeln durch Anwendung eines konjunktiven Operators (AND- oder OR-Operator). Danach werden die Fuzzy-Sätze durch einen Fuzzy-Implikationsoperator (normalerweise Minimum oder Produkt) abgeleitet. Eine gleiche Anzahl von Ausgabesätze wie in den vordefinierten Regeln wird in dieser Stelle erzeugt und am Ende werden diese Gruppen von Ausgabe durch einen Aggregationsoperator (Maximum, Summe, normalisierte Summe, OR-Wahrscheinlichkeit) aggregiert. 
\item  Schließlich wird die Fuzzy-Ausgabe unter Verwendung der Zugehörigkeitsfunktionen in dem Defuzzifizierungsschritt auf eine scharfe Ausgabe abgebildet. Wert für jede Variable wird mithilfe der ausgewählten Defuzzifizierungsmethode berechnet, die wie folgt lautet kann ~\cite{dingle2011artificial}:\\
Schwerpunkt: $\frac{\int x \mu (x) dx}{\int \mu (x) dx}$\\
Schwerpunkt Singleton: $\frac{\sum_{i}x_i\mu_i}{\sum_{i}\mu_i}$\\
Zentrum der Region: $u|\int_{u}^{\infty} \mu(x) dx$\\
Rightmost Maximum: $argmax_x [\mu (x) = max (\mu(x))]$\\
Leftmost Maximum: $argmin_x [\mu (x) = max (\mu(x))]$\\
Durchschnittliches Maximum: $mean(x) [\mu (x) = max (\mu(x))]$\\
\end{itemize}
Die Abbildung  \ref{fig:Fuzzy_Example} stellt diese drei Schritte von Fuzzylogik im graphische Bilder dar, um den Prozess einfache zu verstehen. Beispielweise gibt es ein Smart-Thermostat in einem Raum und der Thermostat soll sich an der Raumtemperatur anpassen. Eine Fuzzylogik wird erstellt, wobei die Temperatur Eingabe ist und Öffnungsgrad des Thermotatventils ist Ausgabe (siehe Abbildung ~\ref{fig:Fuzzy_Example}) und der Regel wird wie in Algorithmus ~\ref{algo:fuzzy} definiert. Die Temperatur wird als \glqq{}Low, Medium und High\grqq{} klassifiziert. Wenn die Temperatur von $0$ bis  $20$ Grad ist, wird sie als \glqq{}Low\grqq{} , von $10$ bis $20$ Grad als \glqq{}Medium\grqq{} und von $20$ bis $40$ Grad als \glqq{}High\grqq{} zugeordnet. Bei Öffnungsgrad des Thermotatventils wird von $1$ bis $2$ als \glqq{}Low\grqq{}, von $1$ bis $4$ als \glqq{}Medium\grqq{} und von $3$ nach $5$ als \glqq{}High\grqq{} definiert. Zum Beispiel ist unsere Eingabe der Temperatur $23$ Grad und die befindet sich zwischen \glqq{}Medium\grqq{} und \glqq{}High\grqq{} wie in Abbildung  ~\ref{fig:Fuzzy_Example} zu sehen. Bei $23$ Grad beträgt der Mitgliedschaftsgrad  $0.7$ zur Menge \glqq{}Medium\grqq{} und $0.3$ zu \glqq{}High\grqq{}. Nach der Regel in Algorithmus ~\ref{algo:fuzzy} wird der Öffnungsgrad des Thermotatventils zwischen \glqq{}Low\grqq{} und \glqq{}Medium\grqq{} berechnet und mit der Methode \glqq{}Schwerpunkt\grqq{} soll der Öffnungsgrad des Thermotatventils bei $2.15$ liegen.\\
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{fig/fuzzy.png}
	\caption{Ein Beispiel für Fuzzylogik in drei Schritte. Oben: Die Temperatur von $23$ Grad wird durch Mitgliederfunktionen abgebildete. Mitte: Durch die (IF-ELSE) Regel in Algorithmus \ref{algo:fuzzy} wird eine Ausgabe als Fuzzymenge berechnet. Unten: Ein Schwerpunkt von der gerechneten Ausgabe wird in eine scharfe Ausgabe abgebildet und es ergibt sich 2.15 für das Thermostat.} 
	\label{fig:Fuzzy_Example}
\end{figure}
\begin{algorithm}[H]
\caption{Regel für Raumtemperatur und Einstellung des Thermostates.	}
\label{algo:fuzzy}
\If{temperature IS low}{thermostat IS high;}
\If{temperature IS medium}{thermostat IS medium;}
\If{temperature IS high}{thermostat IS low;}
\end{algorithm}

Die Berechnung und graphische Darstellung von Fuzzylogik in dieser Arbeit werden mit einer Open-Source-Bibliothek, die \glqq jFuzzyLogic\grqq genannt ist, verwendet.
\section{OpenCV Framework}\label{sec:OpenCV}
OpenCV steht für Open-Computer-Vision. Die Bibliothek wird in C und C++ programmiert und kann unter Linux, Windows, MacOS laufen. OpenCV verfügt über Java, Python, Ruby, Mathlab... OpenCV wurde für Recheneffizienz und mit einem starken Fokus auf Echtzeitanwendungen entwickelt. Diese Bibliothek enthält über 500 Funktionen, die viele Bereiche in der Bildverarbeitung einschließlich maschinelles Lernen, neuronale Netze, usw. umfassen\cite{bradski2008learning}. OpenCV vereinfacht den Bildverarbeitungsprozess mit vielen hilfreichen vordefinierten Funktionen. Da es in dieser Arbeit um ein Echtzeitanwendung geht, wird OpenCV benutzt, um die Verarbeitungszeit gering zu halten. Ein weiterer Vorteil ist die kurze Implementierung, deshalb verkürzt sich die Entwicklungszeit.

\section{360° Kamera}
Ziel dieser Arbeit ist die Erstellung einer Anwendung, die mit der Bosch Innen Kamera funktioniert. Die Testvideos wurden mit eine Bosch Innenkamera aufgenommen. Die Bosch 360 Innenkamera kann sich in jede Richtung drehen und schauen. Die Kamera hat Bewegungssensoren, eine Gegensprechanlage für Zwei-Wege-Audio und Infrarot-Nachtsicht, so dass ein Haus zu jeder Zeit beobachtete werden kann. Wenn es etwas wahrnimmt, zeichnet es HD-Material auf dem lokalen Speicher auf und man kann mit Ihrem Telefon Clips oder Live-Filmmaterial ansehen. Mit Hilfe von dieser Kamera kann man sich von der Fern um die alte Menschen oder Kinder kümmern. Außerdem kann die Innenkamera eine Push-Nachricht ans Smartphone in eine kostenlose App schicken. Dank integrierten Bewegungsmeldern kann die Kamera eine Bewegung verfolgen und sich in die Richtung der entdeckten Bewegung drehen. Das hilft meiner Arbeit bei der Lokalisierung einer Person im Raum. Die Kamera hat zwei Vorteile, die hier gut für diese Arbeit anwendet werden können, nämlich die Fähigkeit, sich jede Richtung zu drehen und mit Infrarot-Nachtsicht aufzunehmen. Das bedeutet, es ist ermöglicht, die Person Tag und Nacht zu betrachten und die außergewöhnliche Situationen genau rechtzeitig zu erkennen. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{fig/BoschInnenkamera.jpg}
	\caption{Bosch 360° Kamera (Quelle: www.bosch-smarthome.com) } 
	\label{fig:BoschInnenCam}
\end{figure}